{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts import tt\n",
    "from scripts import kb\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                       name column_name  n_tuples  missing_perc  uniqueness  \\\n0                   abalone      Length    4177.0      0.497662    0.061113   \n1                   abalone      Length    4177.0      0.497662    0.061113   \n2                   abalone      Length    4177.0      0.497662    0.061113   \n3                   abalone      Length    4177.0      0.497662    0.061113   \n4                   abalone      Length    4177.0      0.497662    0.061113   \n...                     ...         ...       ...           ...         ...   \n3655  wall-robot-navigation          V4    5456.0      0.048850    0.336587   \n3656  wall-robot-navigation          V4    5456.0      0.048850    0.336587   \n3657  wall-robot-navigation          V4    5456.0      0.048850    0.336587   \n3658  wall-robot-navigation          V4    5456.0      0.048850    0.336587   \n3659  wall-robot-navigation          V4    5456.0      0.048850    0.336587   \n\n           min     max      mean    median       std  ...        ml_algorithm  \\\n0     0.113125  0.8025  0.524012  0.543125  0.119525  ...        DecisionTree   \n1     0.113125  0.8025  0.524012  0.543125  0.119525  ...  LogisticRegression   \n2     0.113125  0.8025  0.524012  0.543125  0.119525  ...                 KNN   \n3     0.113125  0.8025  0.524012  0.543125  0.119525  ...        RandomForest   \n4     0.113125  0.8025  0.524012  0.543125  0.119525  ...            AdaBoost   \n...        ...     ...       ...       ...       ...  ...                 ...   \n3655  0.367000  5.0000  1.272325  1.066375  0.820013  ...  LogisticRegression   \n3656  0.367000  5.0000  1.272325  1.066375  0.820013  ...                 KNN   \n3657  0.367000  5.0000  1.272325  1.066375  0.820013  ...        RandomForest   \n3658  0.367000  5.0000  1.272325  1.066375  0.820013  ...            AdaBoost   \n3659  0.367000  5.0000  1.272325  1.066375  0.820013  ...                 SVC   \n\n      impute_standard  impute_mean  impute_median  impute_random  impute_knn  \\\n0            0.167049     0.167073       0.165375       0.164723    0.163803   \n1            0.117011     0.168726       0.165850       0.144390    0.161175   \n2            0.161131     0.165931       0.158960       0.158579    0.163291   \n3            0.173563     0.176447       0.176724       0.174375    0.173512   \n4            0.090465     0.086661       0.087688       0.082144    0.093344   \n...               ...          ...            ...            ...         ...   \n3655         0.964525     0.964453       0.964608       0.964448    0.964648   \n3656         0.974417     0.975874       0.976368       0.974856    0.977297   \n3657         0.999349     0.999138       0.999330       0.999253    0.999177   \n3658         0.780567     0.780567       0.780567       0.780567    0.780567   \n3659         0.954995     0.952725       0.949063       0.947955    0.948490   \n\n      impute_mice  impute_linear_regression  impute_random_forest  \\\n0        0.162692                  0.163265              0.161920   \n1        0.165395                  0.165437              0.165440   \n2        0.162156                  0.161755              0.161918   \n3        0.173533                  0.172991              0.172540   \n4        0.094091                  0.094116              0.094014   \n...           ...                       ...                   ...   \n3655     0.964600                  0.964600              0.964587   \n3656     0.976923                  0.976923              0.976443   \n3657     0.999215                  0.999272              0.999272   \n3658     0.780567                  0.780567              0.780567   \n3659     0.953413                  0.951623              0.953224   \n\n      impute_cmeans  \n0          0.165265  \n1          0.165546  \n2          0.159667  \n3          0.176008  \n4          0.092528  \n...             ...  \n3655       0.964621  \n3656       0.975834  \n3657       0.999272  \n3658       0.780567  \n3659       0.954452  \n\n[3660 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>column_name</th>\n      <th>n_tuples</th>\n      <th>missing_perc</th>\n      <th>uniqueness</th>\n      <th>min</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>std</th>\n      <th>...</th>\n      <th>ml_algorithm</th>\n      <th>impute_standard</th>\n      <th>impute_mean</th>\n      <th>impute_median</th>\n      <th>impute_random</th>\n      <th>impute_knn</th>\n      <th>impute_mice</th>\n      <th>impute_linear_regression</th>\n      <th>impute_random_forest</th>\n      <th>impute_cmeans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone</td>\n      <td>Length</td>\n      <td>4177.0</td>\n      <td>0.497662</td>\n      <td>0.061113</td>\n      <td>0.113125</td>\n      <td>0.8025</td>\n      <td>0.524012</td>\n      <td>0.543125</td>\n      <td>0.119525</td>\n      <td>...</td>\n      <td>DecisionTree</td>\n      <td>0.167049</td>\n      <td>0.167073</td>\n      <td>0.165375</td>\n      <td>0.164723</td>\n      <td>0.163803</td>\n      <td>0.162692</td>\n      <td>0.163265</td>\n      <td>0.161920</td>\n      <td>0.165265</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone</td>\n      <td>Length</td>\n      <td>4177.0</td>\n      <td>0.497662</td>\n      <td>0.061113</td>\n      <td>0.113125</td>\n      <td>0.8025</td>\n      <td>0.524012</td>\n      <td>0.543125</td>\n      <td>0.119525</td>\n      <td>...</td>\n      <td>LogisticRegression</td>\n      <td>0.117011</td>\n      <td>0.168726</td>\n      <td>0.165850</td>\n      <td>0.144390</td>\n      <td>0.161175</td>\n      <td>0.165395</td>\n      <td>0.165437</td>\n      <td>0.165440</td>\n      <td>0.165546</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone</td>\n      <td>Length</td>\n      <td>4177.0</td>\n      <td>0.497662</td>\n      <td>0.061113</td>\n      <td>0.113125</td>\n      <td>0.8025</td>\n      <td>0.524012</td>\n      <td>0.543125</td>\n      <td>0.119525</td>\n      <td>...</td>\n      <td>KNN</td>\n      <td>0.161131</td>\n      <td>0.165931</td>\n      <td>0.158960</td>\n      <td>0.158579</td>\n      <td>0.163291</td>\n      <td>0.162156</td>\n      <td>0.161755</td>\n      <td>0.161918</td>\n      <td>0.159667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone</td>\n      <td>Length</td>\n      <td>4177.0</td>\n      <td>0.497662</td>\n      <td>0.061113</td>\n      <td>0.113125</td>\n      <td>0.8025</td>\n      <td>0.524012</td>\n      <td>0.543125</td>\n      <td>0.119525</td>\n      <td>...</td>\n      <td>RandomForest</td>\n      <td>0.173563</td>\n      <td>0.176447</td>\n      <td>0.176724</td>\n      <td>0.174375</td>\n      <td>0.173512</td>\n      <td>0.173533</td>\n      <td>0.172991</td>\n      <td>0.172540</td>\n      <td>0.176008</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abalone</td>\n      <td>Length</td>\n      <td>4177.0</td>\n      <td>0.497662</td>\n      <td>0.061113</td>\n      <td>0.113125</td>\n      <td>0.8025</td>\n      <td>0.524012</td>\n      <td>0.543125</td>\n      <td>0.119525</td>\n      <td>...</td>\n      <td>AdaBoost</td>\n      <td>0.090465</td>\n      <td>0.086661</td>\n      <td>0.087688</td>\n      <td>0.082144</td>\n      <td>0.093344</td>\n      <td>0.094091</td>\n      <td>0.094116</td>\n      <td>0.094014</td>\n      <td>0.092528</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3655</th>\n      <td>wall-robot-navigation</td>\n      <td>V4</td>\n      <td>5456.0</td>\n      <td>0.048850</td>\n      <td>0.336587</td>\n      <td>0.367000</td>\n      <td>5.0000</td>\n      <td>1.272325</td>\n      <td>1.066375</td>\n      <td>0.820013</td>\n      <td>...</td>\n      <td>LogisticRegression</td>\n      <td>0.964525</td>\n      <td>0.964453</td>\n      <td>0.964608</td>\n      <td>0.964448</td>\n      <td>0.964648</td>\n      <td>0.964600</td>\n      <td>0.964600</td>\n      <td>0.964587</td>\n      <td>0.964621</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>wall-robot-navigation</td>\n      <td>V4</td>\n      <td>5456.0</td>\n      <td>0.048850</td>\n      <td>0.336587</td>\n      <td>0.367000</td>\n      <td>5.0000</td>\n      <td>1.272325</td>\n      <td>1.066375</td>\n      <td>0.820013</td>\n      <td>...</td>\n      <td>KNN</td>\n      <td>0.974417</td>\n      <td>0.975874</td>\n      <td>0.976368</td>\n      <td>0.974856</td>\n      <td>0.977297</td>\n      <td>0.976923</td>\n      <td>0.976923</td>\n      <td>0.976443</td>\n      <td>0.975834</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>wall-robot-navigation</td>\n      <td>V4</td>\n      <td>5456.0</td>\n      <td>0.048850</td>\n      <td>0.336587</td>\n      <td>0.367000</td>\n      <td>5.0000</td>\n      <td>1.272325</td>\n      <td>1.066375</td>\n      <td>0.820013</td>\n      <td>...</td>\n      <td>RandomForest</td>\n      <td>0.999349</td>\n      <td>0.999138</td>\n      <td>0.999330</td>\n      <td>0.999253</td>\n      <td>0.999177</td>\n      <td>0.999215</td>\n      <td>0.999272</td>\n      <td>0.999272</td>\n      <td>0.999272</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>wall-robot-navigation</td>\n      <td>V4</td>\n      <td>5456.0</td>\n      <td>0.048850</td>\n      <td>0.336587</td>\n      <td>0.367000</td>\n      <td>5.0000</td>\n      <td>1.272325</td>\n      <td>1.066375</td>\n      <td>0.820013</td>\n      <td>...</td>\n      <td>AdaBoost</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n      <td>0.780567</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>wall-robot-navigation</td>\n      <td>V4</td>\n      <td>5456.0</td>\n      <td>0.048850</td>\n      <td>0.336587</td>\n      <td>0.367000</td>\n      <td>5.0000</td>\n      <td>1.272325</td>\n      <td>1.066375</td>\n      <td>0.820013</td>\n      <td>...</td>\n      <td>SVC</td>\n      <td>0.954995</td>\n      <td>0.952725</td>\n      <td>0.949063</td>\n      <td>0.947955</td>\n      <td>0.948490</td>\n      <td>0.953413</td>\n      <td>0.951623</td>\n      <td>0.953224</td>\n      <td>0.954452</td>\n    </tr>\n  </tbody>\n</table>\n<p>3660 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_completeness = kb.get_kb_completeness()\n",
    "kb_completeness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "techniques = ['impute_standard','impute_mean','impute_median','impute_random','impute_knn','impute_mice','impute_linear_regression','impute_random_forest','impute_cmeans']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       impute_standard  impute_mean  impute_median  impute_random  \\\ncount      3660.000000  3660.000000    3660.000000    3660.000000   \nmean          0.738650     0.741869       0.741930       0.733998   \nstd           0.207447     0.205807       0.206222       0.205974   \nmin           0.059867     0.059867       0.059867       0.059867   \n25%           0.646555     0.650727       0.649278       0.643199   \n50%           0.780567     0.783010       0.784090       0.775282   \n75%           0.910451     0.913734       0.912523       0.893749   \nmax           1.000000     1.000000       1.000000       1.000000   \n\n        impute_knn  impute_mice  impute_linear_regression  \\\ncount  3660.000000  3660.000000               3660.000000   \nmean      0.744570     0.742414                  0.742211   \nstd       0.205567     0.205937                  0.205889   \nmin       0.059867     0.059867                  0.059867   \n25%       0.653315     0.650926                  0.650590   \n50%       0.784378     0.784017                  0.783849   \n75%       0.926413     0.916514                  0.915938   \nmax       1.000000     1.000000                  1.000000   \n\n       impute_random_forest  impute_cmeans  \ncount           3660.000000    3660.000000  \nmean               0.745003       0.742603  \nstd                0.205428       0.205703  \nmin                0.059867       0.059867  \n25%                0.651931       0.651120  \n50%                0.784545       0.783566  \n75%                0.928210       0.914930  \nmax                1.000000       1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>impute_standard</th>\n      <th>impute_mean</th>\n      <th>impute_median</th>\n      <th>impute_random</th>\n      <th>impute_knn</th>\n      <th>impute_mice</th>\n      <th>impute_linear_regression</th>\n      <th>impute_random_forest</th>\n      <th>impute_cmeans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.738650</td>\n      <td>0.741869</td>\n      <td>0.741930</td>\n      <td>0.733998</td>\n      <td>0.744570</td>\n      <td>0.742414</td>\n      <td>0.742211</td>\n      <td>0.745003</td>\n      <td>0.742603</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.207447</td>\n      <td>0.205807</td>\n      <td>0.206222</td>\n      <td>0.205974</td>\n      <td>0.205567</td>\n      <td>0.205937</td>\n      <td>0.205889</td>\n      <td>0.205428</td>\n      <td>0.205703</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n      <td>0.059867</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.646555</td>\n      <td>0.650727</td>\n      <td>0.649278</td>\n      <td>0.643199</td>\n      <td>0.653315</td>\n      <td>0.650926</td>\n      <td>0.650590</td>\n      <td>0.651931</td>\n      <td>0.651120</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.780567</td>\n      <td>0.783010</td>\n      <td>0.784090</td>\n      <td>0.775282</td>\n      <td>0.784378</td>\n      <td>0.784017</td>\n      <td>0.783849</td>\n      <td>0.784545</td>\n      <td>0.783566</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.910451</td>\n      <td>0.913734</td>\n      <td>0.912523</td>\n      <td>0.893749</td>\n      <td>0.926413</td>\n      <td>0.916514</td>\n      <td>0.915938</td>\n      <td>0.928210</td>\n      <td>0.914930</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_completeness[techniques].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "### differenze di performance\n",
    "\n",
    "### differenza di impatto con varianza 0.2 (20%)\n",
    "### è da provare sia kb_performance sia kb_impact"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abalone: 0.6046409964435673\n",
      "abalone: 0.6010158738722485\n",
      "abalone: 0.6011594040479842\n",
      "abalone: 0.5978559877935347\n",
      "abalone: 0.6045007912871799\n",
      "abalone: 0.6031662640767531\n",
      "abalone: 0.6023569503222231\n",
      "abalone: 0.6024829920264335\n",
      "abalone: 0.6011319398186054\n",
      "abalone: 0.5880585436007926\n",
      "abalone: 0.5485682223554627\n",
      "abalone: 0.5494882196372771\n",
      "abalone: 0.5556874157627225\n",
      "abalone: 0.5550186243155286\n",
      "abalone: 0.5470099089595695\n",
      "abalone: 0.5464264644176892\n",
      "abalone: 0.549634832745269\n",
      "abalone: 0.5472859846399623\n",
      "abalone: 0.600682445278963\n",
      "abalone: 0.603113428156302\n",
      "abalone: 0.6050798725910259\n",
      "abalone: 0.601101602905646\n",
      "abalone: 0.6046929940668395\n",
      "abalone: 0.6045439639803258\n",
      "abalone: 0.604690855389278\n",
      "abalone: 0.6043668510858995\n",
      "abalone: 0.6042638147607012\n",
      "abalone: 0.6095598175700948\n",
      "abalone: 0.6073399278175904\n",
      "abalone: 0.6087664606703068\n",
      "abalone: 0.6043326875335077\n",
      "abalone: 0.6095057296854001\n",
      "abalone: 0.6094944815523982\n",
      "abalone: 0.6088019437881648\n",
      "abalone: 0.6081436588795972\n",
      "abalone: 0.6080886628680112\n",
      "abalone: 0.6379506042126101\n",
      "abalone: 0.6342043300934715\n",
      "abalone: 0.6341476321605323\n",
      "abalone: 0.630913358037999\n",
      "abalone: 0.6315903588036327\n",
      "abalone: 0.6327908883753416\n",
      "abalone: 0.6324120488425633\n",
      "abalone: 0.6331171058106889\n",
      "abalone: 0.63299419118647\n",
      "abalone: 0.5692416130152109\n",
      "abalone: 0.5438173085803527\n",
      "abalone: 0.5449359667774372\n",
      "abalone: 0.5506233402106795\n",
      "abalone: 0.5536180309262894\n",
      "abalone: 0.5462855558378713\n",
      "abalone: 0.5460758118681102\n",
      "abalone: 0.5519002272261744\n",
      "abalone: 0.5450441080802543\n",
      "BachChoralHarmony: 0.35603185272161275\n",
      "BachChoralHarmony: 0.3570149804612563\n",
      "BachChoralHarmony: 0.3544890651478323\n",
      "BachChoralHarmony: 0.3516798471475375\n",
      "BachChoralHarmony: 0.3595851953895696\n",
      "BachChoralHarmony: 0.3600417650574952\n",
      "BachChoralHarmony: 0.35940334337467666\n",
      "BachChoralHarmony: 0.3587161517481918\n",
      "BachChoralHarmony: 0.3563356690936696\n",
      "BachChoralHarmony: 0.2628958182880157\n",
      "BachChoralHarmony: 0.2718387478005347\n",
      "BachChoralHarmony: 0.27162825096346044\n",
      "BachChoralHarmony: 0.266528995594621\n",
      "BachChoralHarmony: 0.27566237178064407\n",
      "BachChoralHarmony: 0.2730135966077374\n",
      "BachChoralHarmony: 0.27292112591086737\n",
      "BachChoralHarmony: 0.2757122269864167\n",
      "BachChoralHarmony: 0.27334747812293175\n",
      "BachChoralHarmony: 0.32693822294538144\n",
      "BachChoralHarmony: 0.32734440907965817\n",
      "BachChoralHarmony: 0.3272855437004902\n",
      "BachChoralHarmony: 0.31957945419516504\n",
      "BachChoralHarmony: 0.32822624071320367\n",
      "BachChoralHarmony: 0.32756649101133384\n",
      "BachChoralHarmony: 0.327573087527272\n",
      "BachChoralHarmony: 0.3291052450387088\n",
      "BachChoralHarmony: 0.32739195552331235\n",
      "BachChoralHarmony: 0.33124719889889787\n",
      "BachChoralHarmony: 0.33174943379104577\n",
      "BachChoralHarmony: 0.3304691223669519\n",
      "BachChoralHarmony: 0.3254966383141021\n",
      "BachChoralHarmony: 0.33029749136179504\n",
      "BachChoralHarmony: 0.33104767688876147\n",
      "BachChoralHarmony: 0.3307409916749294\n",
      "BachChoralHarmony: 0.33016759589851896\n",
      "BachChoralHarmony: 0.3312225988650707\n",
      "BachChoralHarmony: 0.6364453896295078\n",
      "BachChoralHarmony: 0.6384592064564565\n",
      "BachChoralHarmony: 0.6378248984318287\n",
      "BachChoralHarmony: 0.6323901700883743\n",
      "BachChoralHarmony: 0.6401573391266792\n",
      "BachChoralHarmony: 0.6389776119878056\n",
      "BachChoralHarmony: 0.6391438886168745\n",
      "BachChoralHarmony: 0.6416746149807878\n",
      "BachChoralHarmony: 0.6383515485005381\n",
      "BachChoralHarmony: 0.18627259663091614\n",
      "BachChoralHarmony: 0.18784395159198677\n",
      "BachChoralHarmony: 0.18563438461804851\n",
      "BachChoralHarmony: 0.18406233630141094\n",
      "BachChoralHarmony: 0.19392388785951856\n",
      "BachChoralHarmony: 0.18976746908425868\n",
      "BachChoralHarmony: 0.18982568561418806\n",
      "BachChoralHarmony: 0.19241077020391628\n",
      "BachChoralHarmony: 0.19001081141562123\n",
      "bank: 0.13529420394941688\n",
      "bank: 0.134293491379789\n",
      "bank: 0.13461644753625504\n",
      "bank: 0.14074618145597886\n",
      "bank: 0.13302581202875444\n",
      "bank: 0.133778544543013\n",
      "bank: 0.13379820918524388\n",
      "bank: 0.13244882455532833\n",
      "bank: 0.13322086911624054\n",
      "bank: 0.16783273285844477\n",
      "bank: 0.15807831533963074\n",
      "bank: 0.1582537044208433\n",
      "bank: 0.16161398390301882\n",
      "bank: 0.15375698437802382\n",
      "bank: 0.15487204536050234\n",
      "bank: 0.154909788821501\n",
      "bank: 0.15185706779619298\n",
      "bank: 0.15571322376726435\n",
      "bank: 0.13333068133909887\n",
      "bank: 0.1323002514973244\n",
      "bank: 0.13419589296441573\n",
      "bank: 0.1376549580218401\n",
      "bank: 0.13312287028655534\n",
      "bank: 0.13178385127382797\n",
      "bank: 0.13172931163452872\n",
      "bank: 0.13251066672160028\n",
      "bank: 0.1321737212951981\n",
      "bank: 0.12695142799405332\n",
      "bank: 0.12594065134617652\n",
      "bank: 0.12751165987336935\n",
      "bank: 0.13319334321688336\n",
      "bank: 0.1265428624655165\n",
      "bank: 0.1264144674256086\n",
      "bank: 0.12608951511264635\n",
      "bank: 0.126606584926431\n",
      "bank: 0.12615386320805475\n",
      "bank: 0.20179152267090825\n",
      "bank: 0.20449538118881735\n",
      "bank: 0.20465198688726136\n",
      "bank: 0.20544398993285676\n",
      "bank: 0.2009611732127879\n",
      "bank: 0.20324567427672688\n",
      "bank: 0.20298256853413\n",
      "bank: 0.19971350491551706\n",
      "bank: 0.20489157998499294\n",
      "bank: 0.1508416194418496\n",
      "bank: 0.1539368048534698\n",
      "bank: 0.15647777258434206\n",
      "bank: 0.16030615428673342\n",
      "bank: 0.15283071923126704\n",
      "bank: 0.15077945691206937\n",
      "bank: 0.15286327962847718\n",
      "bank: 0.15621970427535162\n",
      "bank: 0.15037420695299175\n",
      "cancer: 0.21608387627204356\n",
      "cancer: 0.21662806137299415\n",
      "cancer: 0.2159333292918355\n",
      "cancer: 0.2205076320352738\n",
      "cancer: 0.2150514707977642\n",
      "cancer: 0.2155526531764916\n",
      "cancer: 0.2158859135153705\n",
      "cancer: 0.2152680494507641\n",
      "cancer: 0.21565127602604459\n",
      "cancer: 0.25126250003289985\n",
      "cancer: 0.24182457409313549\n",
      "cancer: 0.23761406859964823\n",
      "cancer: 0.24532319769280453\n",
      "cancer: 0.23872961649322091\n",
      "cancer: 0.2403901125175434\n",
      "cancer: 0.24060654101422252\n",
      "cancer: 0.2367466813691884\n",
      "cancer: 0.2393399542999961\n",
      "cancer: 0.23337535506135001\n",
      "cancer: 0.2331257369930111\n",
      "cancer: 0.23213252307940707\n",
      "cancer: 0.23832885555535607\n",
      "cancer: 0.23110209938715348\n",
      "cancer: 0.23215223581868039\n",
      "cancer: 0.23218000642277933\n",
      "cancer: 0.2301877290470168\n",
      "cancer: 0.23238428790894264\n",
      "cancer: 0.2112814021469634\n",
      "cancer: 0.2113166061796311\n",
      "cancer: 0.20977694984864095\n",
      "cancer: 0.21554410353843229\n",
      "cancer: 0.21117999097626491\n",
      "cancer: 0.21203962898497583\n",
      "cancer: 0.2119178334353863\n",
      "cancer: 0.21124763999501814\n",
      "cancer: 0.2113147901386848\n",
      "cancer: 0.35573312170740284\n",
      "cancer: 0.3555410615179146\n",
      "cancer: 0.35449231920561086\n",
      "cancer: 0.35630147762457687\n",
      "cancer: 0.35295339145143695\n",
      "cancer: 0.35598460701056556\n",
      "cancer: 0.355845652756662\n",
      "cancer: 0.34464074723600674\n",
      "cancer: 0.3565377369164255\n",
      "cancer: 0.31582673981849857\n",
      "cancer: 0.3132680626030968\n",
      "cancer: 0.31393285792379944\n",
      "cancer: 0.31709922861663403\n",
      "cancer: 0.30542089890878665\n",
      "cancer: 0.31079154818129456\n",
      "cancer: 0.3112128051715651\n",
      "cancer: 0.30530590335522007\n",
      "cancer: 0.3089180190128117\n",
      "default of credit card clients: 0.10013343128937353\n",
      "default of credit card clients: 0.09933594275212092\n",
      "default of credit card clients: 0.0993019550615666\n",
      "default of credit card clients: 0.09776240671189912\n",
      "default of credit card clients: 0.09968813892250596\n",
      "default of credit card clients: 0.09916375706954661\n",
      "default of credit card clients: 0.09882460330785257\n",
      "default of credit card clients: 0.0986565117400795\n",
      "default of credit card clients: 0.09879541838463103\n",
      "default of credit card clients: 0.09610163628285744\n",
      "default of credit card clients: 0.10096741818500476\n",
      "default of credit card clients: 0.10168128355906399\n",
      "default of credit card clients: 0.0982425075843776\n",
      "default of credit card clients: 0.1112979816944059\n",
      "default of credit card clients: 0.10498950558479511\n",
      "default of credit card clients: 0.1046826626492625\n",
      "default of credit card clients: 0.11335746362681187\n",
      "default of credit card clients: 0.10375802934408421\n",
      "default of credit card clients: 0.09492066187909624\n",
      "default of credit card clients: 0.09554606084833987\n",
      "default of credit card clients: 0.09514712660920371\n",
      "default of credit card clients: 0.09152009835729034\n",
      "default of credit card clients: 0.09615620535449995\n",
      "default of credit card clients: 0.09582516558164324\n",
      "default of credit card clients: 0.09566877764780228\n",
      "default of credit card clients: 0.09720172253396503\n",
      "default of credit card clients: 0.09542325563104036\n",
      "default of credit card clients: 0.10265045453295227\n",
      "default of credit card clients: 0.10250511241550411\n",
      "default of credit card clients: 0.1022113383303561\n",
      "default of credit card clients: 0.10064234096099499\n",
      "default of credit card clients: 0.10289823540787929\n",
      "default of credit card clients: 0.10282306533831291\n",
      "default of credit card clients: 0.10258527884281395\n",
      "default of credit card clients: 0.10309378919154996\n",
      "default of credit card clients: 0.10219890852092442\n",
      "default of credit card clients: 0.10822214774880247\n",
      "default of credit card clients: 0.10899544188909559\n",
      "default of credit card clients: 0.10871124309577918\n",
      "default of credit card clients: 0.1072390864382763\n",
      "default of credit card clients: 0.10839708532771114\n",
      "default of credit card clients: 0.10932167978587473\n",
      "default of credit card clients: 0.1092417080506799\n",
      "default of credit card clients: 0.1038909704996757\n",
      "default of credit card clients: 0.10954699627539265\n",
      "default of credit card clients: 0.2652309968296038\n",
      "default of credit card clients: 0.2592841558671601\n",
      "default of credit card clients: 0.26533536675927033\n",
      "default of credit card clients: 0.2190138426275043\n",
      "default of credit card clients: 0.23551856266764687\n",
      "default of credit card clients: 0.262769324909907\n",
      "default of credit card clients: 0.2679175683923962\n",
      "default of credit card clients: 0.2540539005039892\n",
      "default of credit card clients: 0.2593495128798255\n",
      "drug: 0.23099851278951394\n",
      "drug: 0.23101408919650407\n",
      "drug: 0.23251876980128272\n",
      "drug: 0.24109361610624885\n",
      "drug: 0.2349201773154899\n",
      "drug: 0.23285501635827924\n",
      "drug: 0.23888781455966368\n",
      "drug: 0.2459895109759817\n",
      "drug: 0.2342629817341858\n",
      "drug: 0.2356476272826408\n",
      "drug: 0.20159336302240374\n",
      "drug: 0.20275205171235772\n",
      "drug: 0.2140565449534536\n",
      "drug: 0.20642181595458828\n",
      "drug: 0.2021585678150737\n",
      "drug: 0.20456931335708667\n",
      "drug: 0.21310038896079597\n",
      "drug: 0.20264550802469009\n",
      "drug: 0.22575517232590395\n",
      "drug: 0.20336601243232266\n",
      "drug: 0.20328721667459299\n",
      "drug: 0.20130295389048414\n",
      "drug: 0.21051623029060118\n",
      "drug: 0.20630979385303375\n",
      "drug: 0.2076656047695733\n",
      "drug: 0.213040371134164\n",
      "drug: 0.20594123795349395\n",
      "drug: 0.22129449196300588\n",
      "drug: 0.2237753829843615\n",
      "drug: 0.22175505900006584\n",
      "drug: 0.232634870799858\n",
      "drug: 0.22355104561780834\n",
      "drug: 0.22303287245501002\n",
      "drug: 0.22503334871574618\n",
      "drug: 0.23483206654388572\n",
      "drug: 0.22023037125512218\n",
      "drug: 0.24023413470797383\n",
      "drug: 0.2582002610323752\n",
      "drug: 0.23907270388270624\n",
      "drug: 0.2447551244735329\n",
      "drug: 0.24427332599985938\n",
      "drug: 0.2510877992145537\n",
      "drug: 0.2437607213024682\n",
      "drug: 0.2496875638395112\n",
      "drug: 0.2523639879462866\n",
      "drug: 0.2097662839446455\n",
      "drug: 0.21305742758725313\n",
      "drug: 0.2151115271733695\n",
      "drug: 0.21013578011339745\n",
      "drug: 0.2090460970481486\n",
      "drug: 0.21375681823645423\n",
      "drug: 0.21491224692195784\n",
      "drug: 0.21686555143386488\n",
      "drug: 0.21126457183370104\n",
      "electricity-normalized: 0.0965046788112127\n",
      "electricity-normalized: 0.09582046498614599\n",
      "electricity-normalized: 0.09611430610280085\n",
      "electricity-normalized: 0.09503908601949794\n",
      "electricity-normalized: 0.09883886354710525\n",
      "electricity-normalized: 0.09580707602952683\n",
      "electricity-normalized: 0.09507077483123444\n",
      "electricity-normalized: 0.09717170463715355\n",
      "electricity-normalized: 0.09526183641790625\n",
      "electricity-normalized: 0.08352871263272879\n",
      "electricity-normalized: 0.0923648583032826\n",
      "electricity-normalized: 0.09584673993582464\n",
      "electricity-normalized: 0.08940080099796606\n",
      "electricity-normalized: 0.09930869851634379\n",
      "electricity-normalized: 0.09277862995691989\n",
      "electricity-normalized: 0.09257314952116494\n",
      "electricity-normalized: 0.09836239162408016\n",
      "electricity-normalized: 0.09339413776031766\n",
      "electricity-normalized: 0.08553375274184354\n",
      "electricity-normalized: 0.08880808143055578\n",
      "electricity-normalized: 0.08854704100054052\n",
      "electricity-normalized: 0.08608733157977505\n",
      "electricity-normalized: 0.08837135569888002\n",
      "electricity-normalized: 0.0891604431296767\n",
      "electricity-normalized: 0.08905778330755589\n",
      "electricity-normalized: 0.08736176132005195\n",
      "electricity-normalized: 0.08872751890166229\n",
      "electricity-normalized: 0.08587460641742971\n",
      "electricity-normalized: 0.08322888003781634\n",
      "electricity-normalized: 0.0831584402765627\n",
      "electricity-normalized: 0.08277087253997516\n",
      "electricity-normalized: 0.08530965554058272\n",
      "electricity-normalized: 0.08571623471914515\n",
      "electricity-normalized: 0.0852741761789429\n",
      "electricity-normalized: 0.08320072178879195\n",
      "electricity-normalized: 0.08474453074965947\n",
      "electricity-normalized: 0.07783369847001673\n",
      "electricity-normalized: 0.07893876301566963\n",
      "electricity-normalized: 0.0782295301086284\n",
      "electricity-normalized: 0.07816586762904983\n",
      "electricity-normalized: 0.08088250110883839\n",
      "electricity-normalized: 0.08133997058771551\n",
      "electricity-normalized: 0.08132922536633977\n",
      "electricity-normalized: 0.08070955509316152\n",
      "electricity-normalized: 0.08053117900374122\n",
      "electricity-normalized: 0.24464879077777066\n",
      "electricity-normalized: 0.23923207219209794\n",
      "electricity-normalized: 0.2364365747151389\n",
      "electricity-normalized: 0.24089047248743298\n",
      "electricity-normalized: 0.24750147840864076\n",
      "electricity-normalized: 0.24126227329997485\n",
      "electricity-normalized: 0.24172886933207077\n",
      "electricity-normalized: 0.24559139656677928\n",
      "electricity-normalized: 0.24328852326058187\n",
      "fried: 0.08375064764992055\n",
      "fried: 0.08404378481199767\n",
      "fried: 0.08404780710747926\n",
      "fried: 0.08465533771273819\n",
      "fried: 0.08764395492520285\n",
      "fried: 0.08346857348746653\n",
      "fried: 0.08351877758834668\n",
      "fried: 0.08711727697942025\n",
      "fried: 0.08402493028535067\n",
      "fried: 0.0840062140149642\n",
      "fried: 0.07707384306460907\n",
      "fried: 0.07688036033917467\n",
      "fried: 0.07538800832957139\n",
      "fried: 0.07999850550699385\n",
      "fried: 0.07796335120273891\n",
      "fried: 0.07808856957424778\n",
      "fried: 0.08049108428584856\n",
      "fried: 0.07715234953310311\n",
      "fried: 0.09280883345099575\n",
      "fried: 0.09174225997324245\n",
      "fried: 0.0917105425623482\n",
      "fried: 0.08943418919745158\n",
      "fried: 0.0920298731112363\n",
      "fried: 0.09152843420168034\n",
      "fried: 0.09152247750843177\n",
      "fried: 0.09298474199375295\n",
      "fried: 0.09181962432658843\n",
      "fried: 0.08383251416174584\n",
      "fried: 0.08385742323358122\n",
      "fried: 0.08373264003199782\n",
      "fried: 0.08317420666240272\n",
      "fried: 0.08482515884026157\n",
      "fried: 0.08396639106648791\n",
      "fried: 0.08399899487342055\n",
      "fried: 0.08524048462120282\n",
      "fried: 0.08400387647498994\n",
      "fried: 0.15740580247576968\n",
      "fried: 0.15963077018090321\n",
      "fried: 0.15942265646407644\n",
      "fried: 0.15748967186274707\n",
      "fried: 0.15576505493597276\n",
      "fried: 0.16206363222618542\n",
      "fried: 0.16189640403509734\n",
      "fried: 0.15512439826003674\n",
      "fried: 0.16067927691110329\n",
      "fried: 0.19558520298551635\n",
      "fried: 0.2090213976857723\n",
      "fried: 0.21526643106640692\n",
      "fried: 0.21381484143343302\n",
      "fried: 0.227976074668174\n",
      "fried: 0.2156562569166067\n",
      "fried: 0.21563930752788502\n",
      "fried: 0.23290922460666663\n",
      "fried: 0.20727976890245814\n",
      "frogs: 0.11069195374784505\n",
      "frogs: 0.1097884332167289\n",
      "frogs: 0.10941341424921186\n",
      "frogs: 0.10875583622738202\n",
      "frogs: 0.1087873855781073\n",
      "frogs: 0.10900489331625983\n",
      "frogs: 0.10872745745953816\n",
      "frogs: 0.1084893251946719\n",
      "frogs: 0.10985352117127176\n",
      "frogs: 0.10670325664276538\n",
      "frogs: 0.0985826344783561\n",
      "frogs: 0.09846012438352998\n",
      "frogs: 0.09653110320039901\n",
      "frogs: 0.10333708384011418\n",
      "frogs: 0.1009945207828114\n",
      "frogs: 0.10060387859826722\n",
      "frogs: 0.10508405865940491\n",
      "frogs: 0.10075712955979405\n",
      "frogs: 0.12019945339347102\n",
      "frogs: 0.11630176894973815\n",
      "frogs: 0.11765542490601859\n",
      "frogs: 0.11448994814336126\n",
      "frogs: 0.11803160914456715\n",
      "frogs: 0.11850434852934053\n",
      "frogs: 0.11842207525825355\n",
      "frogs: 0.11974063170490816\n",
      "frogs: 0.11666878194181285\n",
      "frogs: 0.10494624507993841\n",
      "frogs: 0.1053555515893758\n",
      "frogs: 0.10488782478242152\n",
      "frogs: 0.10289523975207154\n",
      "frogs: 0.10554507292183085\n",
      "frogs: 0.10598408117561808\n",
      "frogs: 0.10631280622576814\n",
      "frogs: 0.1069144695329745\n",
      "frogs: 0.10564380786752148\n",
      "frogs: 0.10816834189501465\n",
      "frogs: 0.10335037891563623\n",
      "frogs: 0.09351633076375665\n",
      "frogs: 0.09978837681719556\n",
      "frogs: 0.11448110208141916\n",
      "frogs: 0.1142557606650506\n",
      "frogs: 0.11450097177996392\n",
      "frogs: 0.1224227636717902\n",
      "frogs: 0.10695061643805147\n",
      "frogs: 0.122836348504175\n",
      "frogs: 0.1299550021151771\n",
      "frogs: 0.12984649023217829\n",
      "frogs: 0.11524915173638232\n",
      "frogs: 0.13731221972823796\n",
      "frogs: 0.13801420640509846\n",
      "frogs: 0.1364750686623428\n",
      "frogs: 0.13827529614135395\n",
      "frogs: 0.1296218746603826\n",
      "german: 0.1806342229223491\n",
      "german: 0.18096639251443403\n",
      "german: 0.18029798658955123\n",
      "german: 0.18105808970685847\n",
      "german: 0.17710624155759316\n",
      "german: 0.18008122343599525\n",
      "german: 0.18057292528080246\n",
      "german: 0.17832468283293765\n",
      "german: 0.18009708422369716\n",
      "german: 0.16472743903575635\n",
      "german: 0.16880412752568363\n",
      "german: 0.16768862007871588\n",
      "german: 0.1647132800325943\n",
      "german: 0.17178821361774171\n",
      "german: 0.1710991488729732\n",
      "german: 0.1710319156022438\n",
      "german: 0.1742102350622847\n",
      "german: 0.1705843636392756\n",
      "german: 0.1733731019971792\n",
      "german: 0.17233219315972187\n",
      "german: 0.17334894865157022\n",
      "german: 0.16993541335548312\n",
      "german: 0.17548457842565376\n",
      "german: 0.17451603988991246\n",
      "german: 0.17456279393549654\n",
      "german: 0.1773024020449219\n",
      "german: 0.1728446752488615\n",
      "german: 0.16679518303138258\n",
      "german: 0.16738814833274185\n",
      "german: 0.16691798288810378\n",
      "german: 0.1645309093635028\n",
      "german: 0.16659111045651198\n",
      "german: 0.1669411062667247\n",
      "german: 0.16741342670051002\n",
      "german: 0.1657375499473649\n",
      "german: 0.1664898679981034\n",
      "german: 0.13744638503559536\n",
      "german: 0.13892444741231885\n",
      "german: 0.13881017541688725\n",
      "german: 0.13875995512121367\n",
      "german: 0.13756356551300936\n",
      "german: 0.13848390212626896\n",
      "german: 0.13737975856075754\n",
      "german: 0.1351784036126495\n",
      "german: 0.14039656593931144\n",
      "german: 0.13251238869373416\n",
      "german: 0.13742424708408868\n",
      "german: 0.13575505935068105\n",
      "german: 0.13974487549526995\n",
      "german: 0.14375103332506445\n",
      "german: 0.14340162616560034\n",
      "german: 0.14394241052150605\n",
      "german: 0.14616920759464466\n",
      "german: 0.1371531059427795\n",
      "house: 0.11876088800561281\n",
      "house: 0.11643743325457756\n",
      "house: 0.11515126967177675\n",
      "house: 0.12065762631015932\n",
      "house: 0.11578855842571664\n",
      "house: 0.11795684185686695\n",
      "house: 0.11755944549455077\n",
      "house: 0.11465711019698868\n",
      "house: 0.11636538799172436\n",
      "house: 0.15663069766679916\n",
      "house: 0.14796985331231374\n",
      "house: 0.14760838467552795\n",
      "house: 0.1512664019482699\n",
      "house: 0.14525063655509332\n",
      "house: 0.14719243714258087\n",
      "house: 0.14690272539501062\n",
      "house: 0.14343654817341187\n",
      "house: 0.14631882888344422\n",
      "house: 0.12067652533537138\n",
      "house: 0.11995499612569041\n",
      "house: 0.1256604029083717\n",
      "house: 0.127828061621708\n",
      "house: 0.12571517769291168\n",
      "house: 0.12291695547036016\n",
      "house: 0.12412605834174793\n",
      "house: 0.12477332761454586\n",
      "house: 0.1197375135437648\n",
      "house: 0.1202750685877393\n",
      "house: 0.11948515397691185\n",
      "house: 0.12141662631231454\n",
      "house: 0.1260330754947534\n",
      "house: 0.1211777502013017\n",
      "house: 0.11988832710805694\n",
      "house: 0.12082219552869553\n",
      "house: 0.12039596853737417\n",
      "house: 0.11883999768970914\n",
      "house: 0.25074278134697336\n",
      "house: 0.2490289957995524\n",
      "house: 0.25099247375492995\n",
      "house: 0.25292551461918156\n",
      "house: 0.24683005335147692\n",
      "house: 0.24763147681373165\n",
      "house: 0.2472061076538288\n",
      "house: 0.24154277296355944\n",
      "house: 0.2516328647202575\n",
      "house: 0.14689249809867852\n",
      "house: 0.15073997472642872\n",
      "house: 0.1501308872410669\n",
      "house: 0.15611063434093272\n",
      "house: 0.15621577450666554\n",
      "house: 0.14930949057145565\n",
      "house: 0.14905266762655864\n",
      "house: 0.15471554759725317\n",
      "house: 0.14948603798020813\n",
      "iris: 0.2095770462197689\n",
      "iris: 0.21112513384898396\n",
      "iris: 0.20837700510791937\n",
      "iris: 0.22302384491426397\n",
      "iris: 0.20925110279117543\n",
      "iris: 0.2129061838312777\n",
      "iris: 0.21050295760434165\n",
      "iris: 0.21028087530205308\n",
      "iris: 0.20797263671587035\n",
      "iris: 0.22127214379266608\n",
      "iris: 0.16275625501472538\n",
      "iris: 0.1641679476114883\n",
      "iris: 0.17721768904386692\n",
      "iris: 0.1775050937081975\n",
      "iris: 0.1651574928602104\n",
      "iris: 0.1657704614415041\n",
      "iris: 0.17927588539163047\n",
      "iris: 0.16960558573970078\n",
      "iris: 0.1940699664439706\n",
      "iris: 0.18413176465501566\n",
      "iris: 0.18367876170437858\n",
      "iris: 0.19736330561049797\n",
      "iris: 0.18932627961331958\n",
      "iris: 0.18429371752797777\n",
      "iris: 0.18639838067606593\n",
      "iris: 0.1913708457936188\n",
      "iris: 0.17952864573572422\n",
      "iris: 0.19682064216070505\n",
      "iris: 0.19813886287268234\n",
      "iris: 0.19575875226851155\n",
      "iris: 0.21112272213519262\n",
      "iris: 0.1995959734349671\n",
      "iris: 0.20097602596103267\n",
      "iris: 0.20140505370811573\n",
      "iris: 0.20245783917926044\n",
      "iris: 0.19785429173730662\n",
      "iris: 0.2052895590948137\n",
      "iris: 0.21017358534860278\n",
      "iris: 0.20684077431311257\n",
      "iris: 0.21415518340368847\n",
      "iris: 0.21660351975272885\n",
      "iris: 0.20862656193024365\n",
      "iris: 0.20879683633771723\n",
      "iris: 0.21782463551646603\n",
      "iris: 0.20355341952216813\n",
      "iris: 0.137779806180856\n",
      "iris: 0.13491524165338226\n",
      "iris: 0.13529886084371265\n",
      "iris: 0.13158516832964104\n",
      "iris: 0.14057267669556167\n",
      "iris: 0.13678141581070508\n",
      "iris: 0.13620014377353923\n",
      "iris: 0.14416880230905424\n",
      "iris: 0.1376613539403502\n",
      "letter: 0.4724968206495231\n",
      "letter: 0.4689134401262564\n",
      "letter: 0.4694227174306119\n",
      "letter: 0.48293517951019405\n",
      "letter: 0.4679160032888188\n",
      "letter: 0.4670350415768476\n",
      "letter: 0.4665876907348228\n",
      "letter: 0.4666079923539902\n",
      "letter: 0.4676341058691256\n",
      "letter: 0.5259322102660031\n",
      "letter: 0.5116440538486047\n",
      "letter: 0.5144342469924983\n",
      "letter: 0.5170640609406046\n",
      "letter: 0.5076342751149113\n",
      "letter: 0.5074880498921683\n",
      "letter: 0.5070475625737495\n",
      "letter: 0.5036230345962476\n",
      "letter: 0.511150313161522\n",
      "letter: 0.47319642232300707\n",
      "letter: 0.47219934196961016\n",
      "letter: 0.47645986296159343\n",
      "letter: 0.4787792714241602\n",
      "letter: 0.4728022082105558\n",
      "letter: 0.471084152875968\n",
      "letter: 0.4709278668296673\n",
      "letter: 0.4724604479432487\n",
      "letter: 0.4720938973121776\n",
      "letter: 0.4763159590505983\n",
      "letter: 0.47270513952656473\n",
      "letter: 0.47459197814766585\n",
      "letter: 0.48752465587673804\n",
      "letter: 0.47154892728841774\n",
      "letter: 0.47206195722878647\n",
      "letter: 0.471855566301875\n",
      "letter: 0.4716961541964214\n",
      "letter: 0.47179698509659607\n",
      "letter: 0.5453339913995408\n",
      "letter: 0.5523109623011496\n",
      "letter: 0.5520571283830435\n",
      "letter: 0.553283966809768\n",
      "letter: 0.5574650390442194\n",
      "letter: 0.5485554814473647\n",
      "letter: 0.5487559673513249\n",
      "letter: 0.558195189078591\n",
      "letter: 0.550599725032331\n",
      "letter: 0.35084410450370845\n",
      "letter: 0.35338905489499917\n",
      "letter: 0.35429436192091185\n",
      "letter: 0.35657071247856675\n",
      "letter: 0.35916362723118145\n",
      "letter: 0.35304498605414153\n",
      "letter: 0.3528948848708149\n",
      "letter: 0.3553978331084926\n",
      "letter: 0.3543082211698307\n",
      "mv: 0.1432450052141537\n",
      "mv: 0.14616035558682733\n",
      "mv: 0.14695997118454054\n",
      "mv: 0.15289011422054355\n",
      "mv: 0.1483791778364411\n",
      "mv: 0.1481481647859553\n",
      "mv: 0.14989076572251409\n",
      "mv: 0.15178256059855605\n",
      "mv: 0.1449413998025772\n",
      "mv: 0.19007533049037612\n",
      "mv: 0.18146744986221663\n",
      "mv: 0.18168739650073987\n",
      "mv: 0.1770116350253806\n",
      "mv: 0.17989587257409567\n",
      "mv: 0.1824930973291197\n",
      "mv: 0.1833248894157038\n",
      "mv: 0.1812943634590391\n",
      "mv: 0.17906114781295068\n",
      "mv: 0.170289459341524\n",
      "mv: 0.16886891853837424\n",
      "mv: 0.16832619715793382\n",
      "mv: 0.17318766157829793\n",
      "mv: 0.16943317341853337\n",
      "mv: 0.1696513488729296\n",
      "mv: 0.16998193926339272\n",
      "mv: 0.17071362836859746\n",
      "mv: 0.16802959882393928\n",
      "mv: 0.1375038466537894\n",
      "mv: 0.13882553562600342\n",
      "mv: 0.13808844825587668\n",
      "mv: 0.14385472934573948\n",
      "mv: 0.13888931705182644\n",
      "mv: 0.13947967875119124\n",
      "mv: 0.14047923196338766\n",
      "mv: 0.14292346469059306\n",
      "mv: 0.13887959143825776\n",
      "mv: 0.20908287511970525\n",
      "mv: 0.21140259276063783\n",
      "mv: 0.2086721097376965\n",
      "mv: 0.21136114820177418\n",
      "mv: 0.21129887818556117\n",
      "mv: 0.2132483516240004\n",
      "mv: 0.21182318303192102\n",
      "mv: 0.2138850858771342\n",
      "mv: 0.2129876485106631\n",
      "mv: 0.08112599205446654\n",
      "mv: 0.07492980752662357\n",
      "mv: 0.0744651537888373\n",
      "mv: 0.0882488936187589\n",
      "mv: 0.07692454885717938\n",
      "mv: 0.07436724749838655\n",
      "mv: 0.07421713589722449\n",
      "mv: 0.0824264926881266\n",
      "mv: 0.0756956242284332\n",
      "numerai28.6: 0.29253094589483\n",
      "numerai28.6: 0.293518672921646\n",
      "numerai28.6: 0.29332909249907585\n",
      "numerai28.6: 0.2855655680373804\n",
      "numerai28.6: 0.29261480283483626\n",
      "numerai28.6: 0.29238000714610773\n",
      "numerai28.6: 0.2919059748214949\n",
      "numerai28.6: 0.29138725245594577\n",
      "numerai28.6: 0.29207340341111476\n",
      "numerai28.6: 0.24852038351028924\n",
      "numerai28.6: 0.2599349284236352\n",
      "numerai28.6: 0.26119942862156986\n",
      "numerai28.6: 0.25236974597354866\n",
      "numerai28.6: 0.26964477994489255\n",
      "numerai28.6: 0.2653689909367622\n",
      "numerai28.6: 0.26493186236915617\n",
      "numerai28.6: 0.2726655033351076\n",
      "numerai28.6: 0.2649010259295795\n",
      "numerai28.6: 0.27574268762740606\n",
      "numerai28.6: 0.27774761603231485\n",
      "numerai28.6: 0.27714250031347737\n",
      "numerai28.6: 0.2685431769343996\n",
      "numerai28.6: 0.27914644976164027\n",
      "numerai28.6: 0.279546059279776\n",
      "numerai28.6: 0.2791440285443764\n",
      "numerai28.6: 0.282445127473005\n",
      "numerai28.6: 0.27833862498545603\n",
      "numerai28.6: 0.29846841151504366\n",
      "numerai28.6: 0.2996595794258627\n",
      "numerai28.6: 0.29934324584191785\n",
      "numerai28.6: 0.29175197098952593\n",
      "numerai28.6: 0.2989716367961036\n",
      "numerai28.6: 0.2988970509751453\n",
      "numerai28.6: 0.2985546445515489\n",
      "numerai28.6: 0.29938570138605075\n",
      "numerai28.6: 0.2988153812716256\n",
      "numerai28.6: 0.16176929529423606\n",
      "numerai28.6: 0.16264934449574753\n",
      "numerai28.6: 0.16262208346559257\n",
      "numerai28.6: 0.15871019542667922\n",
      "numerai28.6: 0.1666277559555389\n",
      "numerai28.6: 0.16169019439264865\n",
      "numerai28.6: 0.16156220722861575\n",
      "numerai28.6: 0.17594465931920386\n",
      "numerai28.6: 0.1618908180268681\n",
      "numerai28.6: 0.2685260467989092\n",
      "numerai28.6: 0.2736481256064648\n",
      "numerai28.6: 0.2741473202528085\n",
      "numerai28.6: 0.2668135665294684\n",
      "numerai28.6: 0.28026350091442337\n",
      "numerai28.6: 0.27597462371762166\n",
      "numerai28.6: 0.27411883901634043\n",
      "numerai28.6: 0.28068938143164257\n",
      "numerai28.6: 0.2756057626747641\n",
      "phoneme: 0.1203703451462248\n",
      "phoneme: 0.12094713066037728\n",
      "phoneme: 0.12059187730915807\n",
      "phoneme: 0.12774073624665389\n",
      "phoneme: 0.12208428120821652\n",
      "phoneme: 0.12204297393601507\n",
      "phoneme: 0.12269844576162725\n",
      "phoneme: 0.12204385416135682\n",
      "phoneme: 0.11972222331065681\n",
      "phoneme: 0.11355349351554443\n",
      "phoneme: 0.10739813980744244\n",
      "phoneme: 0.10994561653019877\n",
      "phoneme: 0.10444074563534882\n",
      "phoneme: 0.12192492512961693\n",
      "phoneme: 0.1118694370247288\n",
      "phoneme: 0.11155702078551226\n",
      "phoneme: 0.12418497147281696\n",
      "phoneme: 0.11274188872127269\n",
      "phoneme: 0.13176361292607316\n",
      "phoneme: 0.1280387953723416\n",
      "phoneme: 0.12809841685710846\n",
      "phoneme: 0.12871629843801316\n",
      "phoneme: 0.12776952478727424\n",
      "phoneme: 0.12893777069627874\n",
      "phoneme: 0.12894101129639823\n",
      "phoneme: 0.12982569465804877\n",
      "phoneme: 0.12771711510348968\n",
      "phoneme: 0.12710744096913223\n",
      "phoneme: 0.12771816720427284\n",
      "phoneme: 0.12711186557581255\n",
      "phoneme: 0.13120633575006202\n",
      "phoneme: 0.12757095849991978\n",
      "phoneme: 0.12851369789563663\n",
      "phoneme: 0.12891535967478462\n",
      "phoneme: 0.1297752605121506\n",
      "phoneme: 0.12605180685177095\n",
      "phoneme: 0.17737643484381005\n",
      "phoneme: 0.17818275094689318\n",
      "phoneme: 0.1774504255773967\n",
      "phoneme: 0.17706940707797747\n",
      "phoneme: 0.17222666464037348\n",
      "phoneme: 0.17684164978161104\n",
      "phoneme: 0.1767089919024104\n",
      "phoneme: 0.16563248051876356\n",
      "phoneme: 0.17939234995043574\n",
      "phoneme: 0.12248173891170214\n",
      "phoneme: 0.12838181918603953\n",
      "phoneme: 0.13333635394692714\n",
      "phoneme: 0.1312207258409713\n",
      "phoneme: 0.14760639882039356\n",
      "phoneme: 0.13039274491199335\n",
      "phoneme: 0.12906082202905383\n",
      "phoneme: 0.1442223144259569\n",
      "phoneme: 0.1322763364284356\n",
      "ringnorm: 0.10138165046382763\n",
      "ringnorm: 0.1011572223030073\n",
      "ringnorm: 0.10110142646420484\n",
      "ringnorm: 0.10630131677131872\n",
      "ringnorm: 0.10293686559768724\n",
      "ringnorm: 0.10144142219966316\n",
      "ringnorm: 0.10136312038531974\n",
      "ringnorm: 0.10266207327658751\n",
      "ringnorm: 0.10145629182949883\n",
      "ringnorm: 0.13921894525473227\n",
      "ringnorm: 0.1501701588286717\n",
      "ringnorm: 0.1518562810323076\n",
      "ringnorm: 0.14510525279232456\n",
      "ringnorm: 0.1618221412148764\n",
      "ringnorm: 0.15639697714242898\n",
      "ringnorm: 0.15597469639147718\n",
      "ringnorm: 0.16195002528965016\n",
      "ringnorm: 0.15297391081474046\n",
      "ringnorm: 0.09038904274553844\n",
      "ringnorm: 0.09023552308763402\n",
      "ringnorm: 0.09011607904632918\n",
      "ringnorm: 0.08881001929181939\n",
      "ringnorm: 0.09207865352485038\n",
      "ringnorm: 0.09134982076029308\n",
      "ringnorm: 0.09126895652678875\n",
      "ringnorm: 0.09510551756297242\n",
      "ringnorm: 0.09017500730395867\n",
      "ringnorm: 0.09296991944713742\n",
      "ringnorm: 0.09374583874045982\n",
      "ringnorm: 0.0936066470642005\n",
      "ringnorm: 0.09623161287160857\n",
      "ringnorm: 0.09467469953673875\n",
      "ringnorm: 0.0936251411470943\n",
      "ringnorm: 0.09369723116729964\n",
      "ringnorm: 0.09600991265787762\n",
      "ringnorm: 0.0933248439885022\n",
      "ringnorm: 0.10875252156034107\n",
      "ringnorm: 0.10762531122921706\n",
      "ringnorm: 0.1078637734657522\n",
      "ringnorm: 0.10646754873532584\n",
      "ringnorm: 0.10173295350394385\n",
      "ringnorm: 0.10795328067960126\n",
      "ringnorm: 0.10775768113024395\n",
      "ringnorm: 0.0948079468644754\n",
      "ringnorm: 0.1083804131852587\n",
      "ringnorm: 0.09826890120496361\n",
      "ringnorm: 0.10001844343211325\n",
      "ringnorm: 0.09810379893492167\n",
      "ringnorm: 0.10190188123132549\n",
      "ringnorm: 0.10500860502534864\n",
      "ringnorm: 0.10585636318338382\n",
      "ringnorm: 0.10443411354919677\n",
      "ringnorm: 0.10456621155635067\n",
      "ringnorm: 0.10077236487702872\n",
      "Run_or_walk_information: 0.125950240433054\n",
      "Run_or_walk_information: 0.12651357584258974\n",
      "Run_or_walk_information: 0.12724702952013467\n",
      "Run_or_walk_information: 0.12286938986892762\n",
      "Run_or_walk_information: 0.12368219050464757\n",
      "Run_or_walk_information: 0.1261868283090134\n",
      "Run_or_walk_information: 0.1269778454090072\n",
      "Run_or_walk_information: 0.12497661346581476\n",
      "Run_or_walk_information: 0.1271352461186608\n",
      "Run_or_walk_information: 0.12153310976570772\n",
      "Run_or_walk_information: 0.1288390305934321\n",
      "Run_or_walk_information: 0.13151204700937738\n",
      "Run_or_walk_information: 0.12856364729242328\n",
      "Run_or_walk_information: 0.13142448839092258\n",
      "Run_or_walk_information: 0.13352808308416486\n",
      "Run_or_walk_information: 0.1333687801837924\n",
      "Run_or_walk_information: 0.1305942385838321\n",
      "Run_or_walk_information: 0.13136856898603846\n",
      "Run_or_walk_information: 0.13754015277993473\n",
      "Run_or_walk_information: 0.1343754933962216\n",
      "Run_or_walk_information: 0.13443381976528535\n",
      "Run_or_walk_information: 0.13023145818727175\n",
      "Run_or_walk_information: 0.1325208968611666\n",
      "Run_or_walk_information: 0.13471147815400433\n",
      "Run_or_walk_information: 0.13478094885269343\n",
      "Run_or_walk_information: 0.13247768119485598\n",
      "Run_or_walk_information: 0.13389562409225517\n",
      "Run_or_walk_information: 0.11884677986293156\n",
      "Run_or_walk_information: 0.11884806095886767\n",
      "Run_or_walk_information: 0.11879883215864798\n",
      "Run_or_walk_information: 0.11626187843103132\n",
      "Run_or_walk_information: 0.11759946045204098\n",
      "Run_or_walk_information: 0.11873056297294968\n",
      "Run_or_walk_information: 0.11904537037212613\n",
      "Run_or_walk_information: 0.1186023247155568\n",
      "Run_or_walk_information: 0.11923965099666739\n",
      "Run_or_walk_information: 0.2227410663100638\n",
      "Run_or_walk_information: 0.22262649822008435\n",
      "Run_or_walk_information: 0.2225683566894027\n",
      "Run_or_walk_information: 0.219350896388341\n",
      "Run_or_walk_information: 0.22031786008466742\n",
      "Run_or_walk_information: 0.22367080357885788\n",
      "Run_or_walk_information: 0.2234406695533065\n",
      "Run_or_walk_information: 0.22060425046372506\n",
      "Run_or_walk_information: 0.22395961482619944\n",
      "Run_or_walk_information: 0.30840941709895264\n",
      "Run_or_walk_information: 0.30047542206050865\n",
      "Run_or_walk_information: 0.30835305548702563\n",
      "Run_or_walk_information: 0.26253344991426364\n",
      "Run_or_walk_information: 0.24033333658207898\n",
      "Run_or_walk_information: 0.32763782389991825\n",
      "Run_or_walk_information: 0.32805561694514973\n",
      "Run_or_walk_information: 0.25459647517881834\n",
      "Run_or_walk_information: 0.3153780655570837\n",
      "shuttle: 0.18564431949531532\n",
      "shuttle: 0.18655373930420935\n",
      "shuttle: 0.187730898178299\n",
      "shuttle: 0.1908492920493191\n",
      "shuttle: 0.18659380948726526\n",
      "shuttle: 0.1868253967840292\n",
      "shuttle: 0.18851867067241318\n",
      "shuttle: 0.18903697729073385\n",
      "shuttle: 0.187623426214674\n",
      "shuttle: 0.16660546501381154\n",
      "shuttle: 0.12993253487244222\n",
      "shuttle: 0.12887352406412578\n",
      "shuttle: 0.14791981672685153\n",
      "shuttle: 0.1332805942952069\n",
      "shuttle: 0.12868144227181394\n",
      "shuttle: 0.12953855940263762\n",
      "shuttle: 0.1375657399716024\n",
      "shuttle: 0.13696481885426698\n",
      "shuttle: 0.20976781125708693\n",
      "shuttle: 0.2048507753275512\n",
      "shuttle: 0.20503886617821948\n",
      "shuttle: 0.20902249932645237\n",
      "shuttle: 0.2041821218034891\n",
      "shuttle: 0.20455592973655728\n",
      "shuttle: 0.2047753359917059\n",
      "shuttle: 0.20444103269706643\n",
      "shuttle: 0.2043771854611931\n",
      "shuttle: 0.1758469850884345\n",
      "shuttle: 0.17695579906447906\n",
      "shuttle: 0.17641193705355487\n",
      "shuttle: 0.1809869053414367\n",
      "shuttle: 0.17694959815348038\n",
      "shuttle: 0.17686956169196558\n",
      "shuttle: 0.17771342657260025\n",
      "shuttle: 0.17899241944522912\n",
      "shuttle: 0.1765626975619659\n",
      "shuttle: 0.19007283125809335\n",
      "shuttle: 0.19452017069810168\n",
      "shuttle: 0.19060586854274408\n",
      "shuttle: 0.1966812145949032\n",
      "shuttle: 0.19813175748446746\n",
      "shuttle: 0.19469956060885435\n",
      "shuttle: 0.19292177734640906\n",
      "shuttle: 0.1990763743534661\n",
      "shuttle: 0.19576227796467746\n",
      "shuttle: 0.15243150083337406\n",
      "shuttle: 0.14497708791998215\n",
      "shuttle: 0.14358479400370838\n",
      "shuttle: 0.1655378579114904\n",
      "shuttle: 0.1796619431045721\n",
      "shuttle: 0.14372681119271127\n",
      "shuttle: 0.14434598113734787\n",
      "shuttle: 0.1777893459151822\n",
      "shuttle: 0.14375619382727695\n",
      "stars: 0.2037545830112556\n",
      "stars: 0.2040693518929304\n",
      "stars: 0.2039732142375959\n",
      "stars: 0.2136862455869315\n",
      "stars: 0.20536296643482488\n",
      "stars: 0.2050502035368097\n",
      "stars: 0.2052863780126752\n",
      "stars: 0.20469981439892426\n",
      "stars: 0.20490271199257082\n",
      "stars: 0.20641784779479358\n",
      "stars: 0.1909983788928432\n",
      "stars: 0.18989763576002905\n",
      "stars: 0.19356484110094352\n",
      "stars: 0.20460212202189573\n",
      "stars: 0.19571279598516364\n",
      "stars: 0.19511843475749757\n",
      "stars: 0.21663983144930493\n",
      "stars: 0.19759892313203584\n",
      "stars: 0.141602376986317\n",
      "stars: 0.13609096417596267\n",
      "stars: 0.1359954179501021\n",
      "stars: 0.1303690289578239\n",
      "stars: 0.14521379615753327\n",
      "stars: 0.14337844495167024\n",
      "stars: 0.1433252154130233\n",
      "stars: 0.1606126818969682\n",
      "stars: 0.13798129042679294\n",
      "stars: 0.1899264390689376\n",
      "stars: 0.1916388546347592\n",
      "stars: 0.19035471114040953\n",
      "stars: 0.19630376078618803\n",
      "stars: 0.19238937686889396\n",
      "stars: 0.1915337279177833\n",
      "stars: 0.19218179034751068\n",
      "stars: 0.1990642937594067\n",
      "stars: 0.18996012972469997\n",
      "stars: 0.34122367861801667\n",
      "stars: 0.3379192383331466\n",
      "stars: 0.33808370741802324\n",
      "stars: 0.33108321228703297\n",
      "stars: 0.3180750201892238\n",
      "stars: 0.33730839052365363\n",
      "stars: 0.33771573206514416\n",
      "stars: 0.2866518457520425\n",
      "stars: 0.3370601266767105\n",
      "stars: 0.2384266409166935\n",
      "stars: 0.24447124296198236\n",
      "stars: 0.2464722288149063\n",
      "stars: 0.24012878569730645\n",
      "stars: 0.2649423309622484\n",
      "stars: 0.26274637930867073\n",
      "stars: 0.26003496242575247\n",
      "stars: 0.2803412986823096\n",
      "stars: 0.26173242925981144\n",
      "visualizing_soil: 0.15210754456255576\n",
      "visualizing_soil: 0.1460417010562096\n",
      "visualizing_soil: 0.14872867657224376\n",
      "visualizing_soil: 0.15036564349202602\n",
      "visualizing_soil: 0.1540723806540703\n",
      "visualizing_soil: 0.1518260244186484\n",
      "visualizing_soil: 0.15259812005591614\n",
      "visualizing_soil: 0.1549473983143518\n",
      "visualizing_soil: 0.14929288877008826\n",
      "visualizing_soil: 0.15638441112442106\n",
      "visualizing_soil: 0.16158866052901433\n",
      "visualizing_soil: 0.16119139977125288\n",
      "visualizing_soil: 0.16881830416016272\n",
      "visualizing_soil: 0.1673638548138658\n",
      "visualizing_soil: 0.1574750075665033\n",
      "visualizing_soil: 0.15794799154918066\n",
      "visualizing_soil: 0.16587617789712902\n",
      "visualizing_soil: 0.1595722290125722\n",
      "visualizing_soil: 0.1806674133942816\n",
      "visualizing_soil: 0.17676462504814183\n",
      "visualizing_soil: 0.1773925771627087\n",
      "visualizing_soil: 0.17608686758355083\n",
      "visualizing_soil: 0.17532361414838488\n",
      "visualizing_soil: 0.17594642260625293\n",
      "visualizing_soil: 0.17624960594978592\n",
      "visualizing_soil: 0.1739706765257165\n",
      "visualizing_soil: 0.17570490441162098\n",
      "visualizing_soil: 0.14288440871336514\n",
      "visualizing_soil: 0.14249528796770408\n",
      "visualizing_soil: 0.14234195630581228\n",
      "visualizing_soil: 0.14165416236519937\n",
      "visualizing_soil: 0.14594503107248535\n",
      "visualizing_soil: 0.1431914477756984\n",
      "visualizing_soil: 0.14364932074858086\n",
      "visualizing_soil: 0.1456690735334627\n",
      "visualizing_soil: 0.14071908849506176\n",
      "visualizing_soil: 0.2814834324049903\n",
      "visualizing_soil: 0.28230094881953127\n",
      "visualizing_soil: 0.28131663034599147\n",
      "visualizing_soil: 0.27662192912263867\n",
      "visualizing_soil: 0.2806711747195031\n",
      "visualizing_soil: 0.2822529296132793\n",
      "visualizing_soil: 0.28202877746000043\n",
      "visualizing_soil: 0.27412261316308434\n",
      "visualizing_soil: 0.27925979858153616\n",
      "visualizing_soil: 0.23155224854806575\n",
      "visualizing_soil: 0.2384195925847442\n",
      "visualizing_soil: 0.24530814285961008\n",
      "visualizing_soil: 0.23848923865066007\n",
      "visualizing_soil: 0.22812734088357975\n",
      "visualizing_soil: 0.23160861885154535\n",
      "visualizing_soil: 0.23227770769968775\n",
      "visualizing_soil: 0.23001182868669426\n",
      "visualizing_soil: 0.22886179144710692\n",
      "wall-robot-navigation: 0.15938814681196048\n",
      "wall-robot-navigation: 0.15729614321739072\n",
      "wall-robot-navigation: 0.15736530879263352\n",
      "wall-robot-navigation: 0.1564714492767902\n",
      "wall-robot-navigation: 0.1742019680219562\n",
      "wall-robot-navigation: 0.1577746334669692\n",
      "wall-robot-navigation: 0.15818952091942065\n",
      "wall-robot-navigation: 0.17428438489086034\n",
      "wall-robot-navigation: 0.1584046669056266\n",
      "wall-robot-navigation: 0.13348578469507\n",
      "wall-robot-navigation: 0.14912355669760563\n",
      "wall-robot-navigation: 0.14750465240174543\n",
      "wall-robot-navigation: 0.14660012979083278\n",
      "wall-robot-navigation: 0.15388232341472427\n",
      "wall-robot-navigation: 0.13957789294466713\n",
      "wall-robot-navigation: 0.13967703758483935\n",
      "wall-robot-navigation: 0.15172408696057055\n",
      "wall-robot-navigation: 0.13986089493557044\n",
      "wall-robot-navigation: 0.16577236959697345\n",
      "wall-robot-navigation: 0.1642460163773547\n",
      "wall-robot-navigation: 0.16445963079526235\n",
      "wall-robot-navigation: 0.15345943776525206\n",
      "wall-robot-navigation: 0.1643103410437026\n",
      "wall-robot-navigation: 0.16409858629050844\n",
      "wall-robot-navigation: 0.16405541519336925\n",
      "wall-robot-navigation: 0.16272940601438257\n",
      "wall-robot-navigation: 0.16430143660301347\n",
      "wall-robot-navigation: 0.16417697397969538\n",
      "wall-robot-navigation: 0.16420804313042842\n",
      "wall-robot-navigation: 0.16380365559512725\n",
      "wall-robot-navigation: 0.1564151719854265\n",
      "wall-robot-navigation: 0.16552532140305623\n",
      "wall-robot-navigation: 0.1633309030502988\n",
      "wall-robot-navigation: 0.16353823930952996\n",
      "wall-robot-navigation: 0.1646609940685889\n",
      "wall-robot-navigation: 0.16387927036979158\n",
      "wall-robot-navigation: 0.18231633663218855\n",
      "wall-robot-navigation: 0.1606616901611195\n",
      "wall-robot-navigation: 0.16038395480232656\n",
      "wall-robot-navigation: 0.16055775908145822\n",
      "wall-robot-navigation: 0.15271644984005642\n",
      "wall-robot-navigation: 0.15546224459647323\n",
      "wall-robot-navigation: 0.15592254125711028\n",
      "wall-robot-navigation: 0.14615181823477952\n",
      "wall-robot-navigation: 0.16077745069346264\n",
      "wall-robot-navigation: 0.15701386020341387\n",
      "wall-robot-navigation: 0.11958222564989744\n",
      "wall-robot-navigation: 0.1337002123076091\n",
      "wall-robot-navigation: 0.1328108718359185\n",
      "wall-robot-navigation: 0.1462608722052184\n",
      "wall-robot-navigation: 0.11410665729738069\n",
      "wall-robot-navigation: 0.11776944149141798\n",
      "wall-robot-navigation: 0.14545937792180388\n",
      "wall-robot-navigation: 0.11631553144334653\n",
      "Done! Final RMSE: 0.20886694731596211\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tt.training_testing_completeness()\n",
    "tt.evaluate_techniques()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                       dataset               model  ranking_eval  \\\n0                    abalone_0        DecisionTree      0.111111   \n1                    abalone_0  LogisticRegression      0.333333   \n2                    abalone_0                 KNN      0.222222   \n3                    abalone_0        RandomForest      0.222222   \n4                    abalone_0            AdaBoost      0.111111   \n...                        ...                 ...           ...   \n3655  wall-robot-navigation_29  LogisticRegression      0.111111   \n3656  wall-robot-navigation_29                 KNN      0.222222   \n3657  wall-robot-navigation_29        RandomForest      0.000000   \n3658  wall-robot-navigation_29            AdaBoost      0.444444   \n3659  wall-robot-navigation_29                 SVC      0.222222   \n\n                                           ranking_real  \\\n0     ['impute_mean' 'impute_standard' 'impute_media...   \n1     ['impute_mean' 'impute_median' 'impute_cmeans'...   \n2     ['impute_mean' 'impute_knn' 'impute_mice' 'imp...   \n3     ['impute_median' 'impute_mean' 'impute_cmeans'...   \n4     ['impute_linear_regression' 'impute_mice' 'imp...   \n...                                                 ...   \n3655  ['impute_knn' 'impute_cmeans' 'impute_median' ...   \n3656  ['impute_knn' 'impute_mice' 'impute_linear_reg...   \n3657  ['impute_standard' 'impute_median' 'impute_lin...   \n3658  ['impute_standard' 'impute_mean' 'impute_media...   \n3659  ['impute_standard' 'impute_cmeans' 'impute_mic...   \n\n                                           ranking_pred  \\\n0     ['impute_standard' 'impute_mean' 'impute_knn' ...   \n1     ['impute_knn' 'impute_mean' 'impute_mice' 'imp...   \n2     ['impute_median' 'impute_mice' 'impute_linear_...   \n3     ['impute_median' 'impute_standard' 'impute_cme...   \n4     ['impute_knn' 'impute_standard' 'impute_median...   \n...                                                 ...   \n3655  ['impute_random_forest' 'impute_knn' 'impute_m...   \n3656  ['impute_random_forest' 'impute_knn' 'impute_c...   \n3657  ['impute_random_forest' 'impute_knn' 'impute_m...   \n3658  ['impute_random_forest' 'impute_knn' 'impute_m...   \n3659  ['impute_random_forest' 'impute_knn' 'impute_m...   \n\n                                             value_real  \\\n0     [0.16707319 0.16704874 0.16537502 0.16526472 0...   \n1     [0.16872575 0.16585032 0.1655464  0.16543962 0...   \n2     [0.16593125 0.16329103 0.16215553 0.1619183  0...   \n3     [0.17672358 0.17644679 0.17600835 0.17437514 0...   \n4     [0.09411561 0.09409112 0.09401387 0.09334411 0...   \n...                                                 ...   \n3655  [0.964648   0.96462096 0.96460825 0.96460037 0...   \n3656  [0.97729731 0.9769229  0.9769229  0.97644329 0...   \n3657  [0.99934886 0.99932996 0.99927241 0.99927236 0...   \n3658  [0.78056659 0.78056659 0.78056659 0.78056659 0...   \n3659  [0.95499468 0.95445163 0.95341345 0.95322383 0...   \n\n                                             value_pred  perc_completeness  \n0     [0.79539105 0.79374983 0.79242218 0.79156877 0...           0.497662  \n1     [0.79056445 0.7877749  0.78704733 0.7869225  0...           0.497662  \n2     [0.78419537 0.78248948 0.78246874 0.78245198 0...           0.497662  \n3     [0.80751399 0.80750866 0.80546981 0.80447213 0...           0.497662  \n4     [0.74057332 0.73841406 0.73751066 0.73670692 0...           0.497662  \n...                                                 ...                ...  \n3655  [0.83770106 0.83527944 0.82620699 0.82473523 0...           0.048850  \n3656  [0.86401913 0.86226973 0.85828151 0.8578658  0...           0.048850  \n3657  [0.88544796 0.88444583 0.88356224 0.88341593 0...           0.048850  \n3658  [0.62941717 0.6103673  0.59846881 0.59558506 0...           0.048850  \n3659  [0.82365567 0.82221815 0.81771453 0.81516312 0...           0.048850  \n\n[3660 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>ranking_eval</th>\n      <th>ranking_real</th>\n      <th>ranking_pred</th>\n      <th>value_real</th>\n      <th>value_pred</th>\n      <th>perc_completeness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone_0</td>\n      <td>DecisionTree</td>\n      <td>0.111111</td>\n      <td>['impute_mean' 'impute_standard' 'impute_media...</td>\n      <td>['impute_standard' 'impute_mean' 'impute_knn' ...</td>\n      <td>[0.16707319 0.16704874 0.16537502 0.16526472 0...</td>\n      <td>[0.79539105 0.79374983 0.79242218 0.79156877 0...</td>\n      <td>0.497662</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone_0</td>\n      <td>LogisticRegression</td>\n      <td>0.333333</td>\n      <td>['impute_mean' 'impute_median' 'impute_cmeans'...</td>\n      <td>['impute_knn' 'impute_mean' 'impute_mice' 'imp...</td>\n      <td>[0.16872575 0.16585032 0.1655464  0.16543962 0...</td>\n      <td>[0.79056445 0.7877749  0.78704733 0.7869225  0...</td>\n      <td>0.497662</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone_0</td>\n      <td>KNN</td>\n      <td>0.222222</td>\n      <td>['impute_mean' 'impute_knn' 'impute_mice' 'imp...</td>\n      <td>['impute_median' 'impute_mice' 'impute_linear_...</td>\n      <td>[0.16593125 0.16329103 0.16215553 0.1619183  0...</td>\n      <td>[0.78419537 0.78248948 0.78246874 0.78245198 0...</td>\n      <td>0.497662</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone_0</td>\n      <td>RandomForest</td>\n      <td>0.222222</td>\n      <td>['impute_median' 'impute_mean' 'impute_cmeans'...</td>\n      <td>['impute_median' 'impute_standard' 'impute_cme...</td>\n      <td>[0.17672358 0.17644679 0.17600835 0.17437514 0...</td>\n      <td>[0.80751399 0.80750866 0.80546981 0.80447213 0...</td>\n      <td>0.497662</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abalone_0</td>\n      <td>AdaBoost</td>\n      <td>0.111111</td>\n      <td>['impute_linear_regression' 'impute_mice' 'imp...</td>\n      <td>['impute_knn' 'impute_standard' 'impute_median...</td>\n      <td>[0.09411561 0.09409112 0.09401387 0.09334411 0...</td>\n      <td>[0.74057332 0.73841406 0.73751066 0.73670692 0...</td>\n      <td>0.497662</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3655</th>\n      <td>wall-robot-navigation_29</td>\n      <td>LogisticRegression</td>\n      <td>0.111111</td>\n      <td>['impute_knn' 'impute_cmeans' 'impute_median' ...</td>\n      <td>['impute_random_forest' 'impute_knn' 'impute_m...</td>\n      <td>[0.964648   0.96462096 0.96460825 0.96460037 0...</td>\n      <td>[0.83770106 0.83527944 0.82620699 0.82473523 0...</td>\n      <td>0.048850</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>wall-robot-navigation_29</td>\n      <td>KNN</td>\n      <td>0.222222</td>\n      <td>['impute_knn' 'impute_mice' 'impute_linear_reg...</td>\n      <td>['impute_random_forest' 'impute_knn' 'impute_c...</td>\n      <td>[0.97729731 0.9769229  0.9769229  0.97644329 0...</td>\n      <td>[0.86401913 0.86226973 0.85828151 0.8578658  0...</td>\n      <td>0.048850</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>wall-robot-navigation_29</td>\n      <td>RandomForest</td>\n      <td>0.000000</td>\n      <td>['impute_standard' 'impute_median' 'impute_lin...</td>\n      <td>['impute_random_forest' 'impute_knn' 'impute_m...</td>\n      <td>[0.99934886 0.99932996 0.99927241 0.99927236 0...</td>\n      <td>[0.88544796 0.88444583 0.88356224 0.88341593 0...</td>\n      <td>0.048850</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>wall-robot-navigation_29</td>\n      <td>AdaBoost</td>\n      <td>0.444444</td>\n      <td>['impute_standard' 'impute_mean' 'impute_media...</td>\n      <td>['impute_random_forest' 'impute_knn' 'impute_m...</td>\n      <td>[0.78056659 0.78056659 0.78056659 0.78056659 0...</td>\n      <td>[0.62941717 0.6103673  0.59846881 0.59558506 0...</td>\n      <td>0.048850</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>wall-robot-navigation_29</td>\n      <td>SVC</td>\n      <td>0.222222</td>\n      <td>['impute_standard' 'impute_cmeans' 'impute_mic...</td>\n      <td>['impute_random_forest' 'impute_knn' 'impute_m...</td>\n      <td>[0.95499468 0.95445163 0.95341345 0.95322383 0...</td>\n      <td>[0.82365567 0.82221815 0.81771453 0.81516312 0...</td>\n      <td>0.048850</td>\n    </tr>\n  </tbody>\n</table>\n<p>3660 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = pd.read_csv(\"../results/techniques_completeness_evaluation_total.csv\")\n",
    "rankings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       ranking_eval  perc_completeness\ncount   3660.000000        3660.000000\nmean       0.175228           0.274866\nstd        0.139593           0.143846\nmin        0.000000           0.040087\n25%        0.111111           0.149875\n50%        0.111111           0.271250\n75%        0.222222           0.400237\nmax        0.777778           0.529162",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ranking_eval</th>\n      <th>perc_completeness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.175228</td>\n      <td>0.274866</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.139593</td>\n      <td>0.143846</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.040087</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.111111</td>\n      <td>0.149875</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.111111</td>\n      <td>0.271250</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.222222</td>\n      <td>0.400237</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.777778</td>\n      <td>0.529162</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings.describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "ranking_eval\n0.111111    1163\n0.222222     969\n0.000000     768\n0.333333     477\n0.444444     193\n0.555556      77\n0.666667       8\n0.777778       5\nName: count, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings.ranking_eval.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "### in media ci becchiamo sempre per il 17% delle posizioni"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_ranking_values_array(s):\n",
    "    s = s.replace(\".        ]\",\".0]\")\n",
    "    s = s.replace(\"   \",\" \")\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\" ]\",\"]\")\n",
    "    s = s.replace(\"\\'\",\"\")\n",
    "    s = s.replace(\"[\",\"\")\n",
    "    s = s.replace(\"]\",\"\")\n",
    "    s = s.replace(\"    \",\" \")\n",
    "    s = s.replace(\"   \",\" \")\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.split(\" \")\n",
    "    s = np.array(s)\n",
    "    s = np.delete(s, np.where(s == ''))\n",
    "    s = s.astype(float)\n",
    "    return s\n",
    "\n",
    "def get_ranking_array(s):\n",
    "    s = s.replace(\".        ]\",\".0]\")\n",
    "    s = s.replace(\"   \",\" \")\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\" ]\",\"]\")\n",
    "    s = s.replace(\"\\'\",\"\")\n",
    "    s = s.replace(\"[\",\"\")\n",
    "    s = s.replace(\"]\",\"\")\n",
    "    s = s.split(\" \")\n",
    "    s = np.array(s)\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "diff = []\n",
    "for i in range(0,len(rankings)):\n",
    "    v = rankings.loc[i].value_real\n",
    "    values = get_ranking_values_array(v)\n",
    "    value_1 = values[0]\n",
    "    value_2 = values[8]\n",
    "    diff.append([rankings.loc[i].dataset,value_1 - value_2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                             0         1\n0                    abalone_0  0.005154\n1                    abalone_0  0.051714\n2                    abalone_0  0.007352\n3                    abalone_0  0.004184\n4                    abalone_0  0.011971\n...                        ...       ...\n3655  wall-robot-navigation_29  0.000200\n3656  wall-robot-navigation_29  0.002881\n3657  wall-robot-navigation_29  0.000211\n3658  wall-robot-navigation_29  0.000000\n3659  wall-robot-navigation_29  0.007039\n\n[3660 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone_0</td>\n      <td>0.005154</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone_0</td>\n      <td>0.051714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone_0</td>\n      <td>0.007352</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone_0</td>\n      <td>0.004184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abalone_0</td>\n      <td>0.011971</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3655</th>\n      <td>wall-robot-navigation_29</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>wall-robot-navigation_29</td>\n      <td>0.002881</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>wall-robot-navigation_29</td>\n      <td>0.000211</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>wall-robot-navigation_29</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>wall-robot-navigation_29</td>\n      <td>0.007039</td>\n    </tr>\n  </tbody>\n</table>\n<p>3660 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pd.DataFrame(diff)\n",
    "diff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "count    3660.000000\nmean        0.022517\nstd         0.036321\nmin         0.000000\n25%         0.003573\n50%         0.010472\n75%         0.024172\nmax         0.323654\nName: 1, dtype: float64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[1].describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(0.010472250000000016)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[1].median()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "### studio delle differenze di performance tra prima e ultima posizione del ranking delle tecniche (esperimenti)\n",
    "### media 2%\n",
    "### mediana 1% (anche il 50%-percentile)\n",
    "### massimo 32%\n",
    "### il 75%-percentile è 2%\n",
    "### relevance: perdiamo l'1% = mediana"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "### AVG PRECISION REC SYS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "relevance = 0.01 ### stabilisco la relevance all'1% (la mediana)\n",
    "N = 3\n",
    "#N = [1,3,5] ### queste di calcolano tutte e 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "### avg precision (rec sys)\n",
    "\n",
    "###  sum(k=1-->N) 1/m * P(k)*rel(k)\n",
    "### where\n",
    "### m is the number of relevant item (the number of technique in a performance threshold), is variable\n",
    "### N is the number of item to recommend. is a variable: top1, top3...\n",
    "### P(k) is the precision at cutoff k\n",
    "### rel(k) is 1 if the item is relevant\n",
    "### P(k)*rel(k) --> +1 if the item is present in the most relevant, +0 otherwise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "precision = []\n",
    "\n",
    "for i in range(0,len(rankings)):\n",
    "    v1 = rankings.loc[i].ranking_real\n",
    "    v2 = rankings.loc[i].ranking_pred\n",
    "    v3 = rankings.loc[i].value_real\n",
    "    v4 = rankings.loc[i].value_pred\n",
    "\n",
    "    ### prendo tutti i valori\n",
    "    rank_real = get_ranking_array(v1)\n",
    "    rank_pred = get_ranking_array(v2)\n",
    "    values_real = get_ranking_values_array(v3)\n",
    "    values_pred = get_ranking_values_array(v4)\n",
    "\n",
    "    ### calcolo m\n",
    "    indexes = np.where(values_real > (values_real[0] - relevance))[0]\n",
    "    m = len(indexes)\n",
    "    ### calcolo precision\n",
    "    P_k = 0\n",
    "    for j in range(0, N):\n",
    "        tech = rank_pred[j]\n",
    "        if tech in rank_real[indexes]:\n",
    "            P_k += 1\n",
    "    precision.append([rankings.loc[i].dataset,rankings.loc[i].model,P_k/m,m])\n",
    "precision = pd.DataFrame(precision,columns=['dataset','model','precision','m'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                       dataset               model  precision  m\n0                    abalone_0        DecisionTree   0.333333  9\n1                    abalone_0  LogisticRegression   0.428571  7\n2                    abalone_0                 KNN   0.333333  9\n3                    abalone_0        RandomForest   0.333333  9\n4                    abalone_0            AdaBoost   0.375000  8\n...                        ...                 ...        ... ..\n3655  wall-robot-navigation_29  LogisticRegression   0.333333  9\n3656  wall-robot-navigation_29                 KNN   0.333333  9\n3657  wall-robot-navigation_29        RandomForest   0.333333  9\n3658  wall-robot-navigation_29            AdaBoost   0.333333  9\n3659  wall-robot-navigation_29                 SVC   0.333333  9\n\n[3660 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>precision</th>\n      <th>m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone_0</td>\n      <td>DecisionTree</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone_0</td>\n      <td>LogisticRegression</td>\n      <td>0.428571</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone_0</td>\n      <td>KNN</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone_0</td>\n      <td>RandomForest</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abalone_0</td>\n      <td>AdaBoost</td>\n      <td>0.375000</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3655</th>\n      <td>wall-robot-navigation_29</td>\n      <td>LogisticRegression</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>wall-robot-navigation_29</td>\n      <td>KNN</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>wall-robot-navigation_29</td>\n      <td>RandomForest</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>wall-robot-navigation_29</td>\n      <td>AdaBoost</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>wall-robot-navigation_29</td>\n      <td>SVC</td>\n      <td>0.333333</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>3660 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "precision\n0.333333    1884\n0.375000     684\n0.000000     235\n1.000000     192\n0.500000     184\n0.428571     153\n0.285714      85\n0.250000      70\n0.400000      55\n0.200000      34\n0.666667      27\n0.600000      21\n0.166667      18\n0.750000      16\n0.142857       2\nName: count, dtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.precision.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "m\n9    1772\n8     711\n2     257\n7     240\n1     223\n6     127\n5     117\n4     108\n3     105\nName: count, dtype: int64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.m.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "         precision            m\ncount  3660.000000  3660.000000\nmean      0.369001     7.143989\nstd       0.183975     2.635926\nmin       0.000000     1.000000\n25%       0.333333     6.000000\n50%       0.333333     8.000000\n75%       0.375000     9.000000\nmax       1.000000     9.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.369001</td>\n      <td>7.143989</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.183975</td>\n      <td>2.635926</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.333333</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.333333</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.375000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>9.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(0.3333333333333333)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.precision.median()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(0.4)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### escludo m = 8, 9, 7, 6\n",
    "precision[precision.m < 6].precision.median()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### la precision si alza, non di molto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "### PRECISION FISSA CON N = m = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "relevance = 0.01 ### stabilisco la relevance all'1% (la mediana)\n",
    "N = 3\n",
    "\n",
    "### stabilisco la relevance allo 0,3% (la mediana)\n",
    "precision = []\n",
    "\n",
    "for i in range(0, len(rankings)):\n",
    "    v1 = rankings.loc[i].ranking_real\n",
    "    v2 = rankings.loc[i].ranking_pred\n",
    "    v3 = rankings.loc[i].value_real\n",
    "    v4 = rankings.loc[i].value_pred\n",
    "\n",
    "    ### prendo tutti i valori\n",
    "    rank_real = get_ranking_array(v1)\n",
    "    rank_pred = get_ranking_array(v2)\n",
    "    values_real = get_ranking_values_array(v3)\n",
    "    values_pred = get_ranking_values_array(v4)\n",
    "\n",
    "    ### calcolo m\n",
    "    indexes = [0,1,2]\n",
    "    #N = len(indexes)\n",
    "    ### calcolo precision\n",
    "    P_k = 0\n",
    "    for j in range(0, N):\n",
    "        tech = rank_pred[j]\n",
    "        if tech in rank_real[indexes]:\n",
    "            P_k += 1\n",
    "    precision.append([rankings.loc[i].dataset, rankings.loc[i].model, P_k / N, N])\n",
    "precision = pd.DataFrame(precision, columns=['dataset', 'model', 'precision','N'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "precision\n0.333333    1718\n0.666667    1087\n0.000000     708\n1.000000     147\nName: count, dtype: int64"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.precision.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "         precision       N\ncount  3660.000000  3660.0\nmean      0.394627     3.0\nstd       0.261927     0.0\nmin       0.000000     3.0\n25%       0.333333     3.0\n50%       0.333333     3.0\n75%       0.666667     3.0\nmax       1.000000     3.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>N</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3660.000000</td>\n      <td>3660.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.394627</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.261927</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.333333</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.333333</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.666667</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(0.3333333333333333)"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.precision.median()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "### forse ha senso qui far variare anche la N insieme alla m:\n",
    "relevance = 0.01\n",
    "#N = 3\n",
    "\n",
    "precision = []\n",
    "\n",
    "for i in range(0, len(rankings)):\n",
    "    v1 = rankings.loc[i].ranking_real\n",
    "    v2 = rankings.loc[i].ranking_pred\n",
    "    v3 = rankings.loc[i].value_real\n",
    "    v4 = rankings.loc[i].value_pred\n",
    "\n",
    "    ### prendo tutti i valori\n",
    "    rank_real = get_ranking_array(v1)\n",
    "    rank_pred = get_ranking_array(v2)\n",
    "    values_real = get_ranking_values_array(v3)\n",
    "    values_pred = get_ranking_values_array(v4)\n",
    "\n",
    "    ### calcolo m\n",
    "    indexes = np.where(values_real > (values_real[0] - relevance))[0]\n",
    "    m = len(indexes)\n",
    "    ### calcolo precision\n",
    "    P_k = 0\n",
    "    for i in range(0, m):\n",
    "        tech = rank_pred[i]\n",
    "        if tech in rank_real[indexes]:\n",
    "            P_k += 1\n",
    "    precision.append([rankings.loc[i].dataset, P_k / m, m])\n",
    "precision = pd.DataFrame(precision, columns=['dataset', 'precision', 'm'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "precision\n1.000000    2573\n0.000000     303\n0.500000     141\n0.857143     132\n0.875000     120\n0.666667      82\n0.833333      56\n0.333333      51\n0.600000      43\n0.714286      37\n0.400000      35\n0.750000      29\n0.800000      27\n0.250000      25\n0.200000       6\nName: count, dtype: int64"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.precision.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "m\n9    1772\n8     711\n2     257\n7     240\n1     223\n6     127\n5     117\n4     108\n3     105\nName: count, dtype: int64"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.m.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "         precision            m\ncount  3660.000000  3660.000000\nmean      0.846176     7.143989\nstd       0.301606     2.635926\nmin       0.000000     1.000000\n25%       0.857143     6.000000\n50%       1.000000     8.000000\n75%       1.000000     9.000000\nmax       1.000000     9.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3660.000000</td>\n      <td>3660.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.846176</td>\n      <td>7.143989</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.301606</td>\n      <td>2.635926</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.857143</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>9.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(1.0)"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.precision.median()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "### sempre precision = 1 con relevance = 0.01\n",
    "### sempre precision = 1 con relevance = 0.005\n",
    "### precision = 0.5 se abbasso la relevance a 0.001\n",
    "### la relevance più adatta potrebbe anche essere 0.005 (metà della mediana)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "### è meglio ragionare sull'impatto a questo punto perchè qui la relevance migliore è 0.01 (mediana) ma ho\n",
    "### precision = 0.33 sia per m variabile che m = 3 fisso\n",
    "### precision = 1 per N e m variabili con la relevance ma perdo molto rispetto all'impatto...\n",
    "### --> siamo più precisi a ragionare sull'impatto anche se i risultati sono abbastanza equivalenti\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
