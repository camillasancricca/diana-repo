{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import algorithms_class as alg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   cp  oldpeak       thal\n0        asymptomatic      2.3        mid\n1    non-anginal pain      3.5       high\n2     atypical angina      1.4       high\n3     atypical angina      0.8       high\n4      typical angina      0.6       high\n..                ...      ...        ...\n298    typical angina      0.2  very high\n299      asymptomatic      1.2  very high\n300    typical angina      3.4  very high\n301    typical angina      1.2  very high\n302   atypical angina      0.0       high\n\n[303 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cp</th>\n      <th>oldpeak</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>asymptomatic</td>\n      <td>2.3</td>\n      <td>mid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>non-anginal pain</td>\n      <td>3.5</td>\n      <td>high</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>atypical angina</td>\n      <td>1.4</td>\n      <td>high</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>atypical angina</td>\n      <td>0.8</td>\n      <td>high</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>typical angina</td>\n      <td>0.6</td>\n      <td>high</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>typical angina</td>\n      <td>0.2</td>\n      <td>very high</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>asymptomatic</td>\n      <td>1.2</td>\n      <td>very high</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>typical angina</td>\n      <td>3.4</td>\n      <td>very high</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>typical angina</td>\n      <td>1.2</td>\n      <td>very high</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>atypical angina</td>\n      <td>0.0</td>\n      <td>high</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../dataset/heart.csv\")\n",
    "target = 'disease'\n",
    "features = df.columns.drop(target)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     oldpeak  cp_asymptomatic  cp_atypical angina  cp_non-anginal pain  \\\n0        2.3             True               False                False   \n1        3.5            False               False                 True   \n2        1.4            False                True                False   \n3        0.8            False                True                False   \n4        0.6            False               False                False   \n..       ...              ...                 ...                  ...   \n298      0.2            False               False                False   \n299      1.2             True               False                False   \n300      3.4            False               False                False   \n301      1.2            False               False                False   \n302      0.0            False                True                False   \n\n     cp_typical angina  thal_high  thal_low  thal_mid  thal_very high  \n0                False      False     False      True           False  \n1                False       True     False     False           False  \n2                False       True     False     False           False  \n3                False       True     False     False           False  \n4                 True       True     False     False           False  \n..                 ...        ...       ...       ...             ...  \n298               True      False     False     False            True  \n299              False      False     False     False            True  \n300               True      False     False     False            True  \n301               True      False     False     False            True  \n302              False       True     False     False           False  \n\n[303 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>oldpeak</th>\n      <th>cp_asymptomatic</th>\n      <th>cp_atypical angina</th>\n      <th>cp_non-anginal pain</th>\n      <th>cp_typical angina</th>\n      <th>thal_high</th>\n      <th>thal_low</th>\n      <th>thal_mid</th>\n      <th>thal_very high</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.3</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.5</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.4</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.8</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.6</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>0.2</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>1.2</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>3.4</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>1.2</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>0.0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = alg.encoding_categorical_variables(X)\n",
    "X_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 0.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [1., 1., 0.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 1.],\n       [1., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 1.],\n       [1., 0., 1.],\n       [0., 1., 0.]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "X_new = SelectKBest(mutual_info_classif, k=3).fit_transform(X_encoded, y)\n",
    "X_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "selected_features = ['cp','oldpeak','thal']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "classifiers = ['DecisionTree','LogisticRegression','KNN','RandomForest','AdaBoost','SVC']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TUNING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for DecisionTree...\n",
      "0.7141126799557032\n",
      "Training for DecisionTree...\n",
      "0.7191724951955996\n",
      "Training for DecisionTree...\n",
      "0.735269313449888\n",
      "Training for DecisionTree...\n",
      "0.7462302243298962\n",
      "Training for DecisionTree...\n",
      "0.732819955432712\n",
      "Training for DecisionTree...\n",
      "0.7324392694140593\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.7326296124233856)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = 'DecisionTree'\n",
    "param = 160\n",
    "perf_mean = []\n",
    "for param in [30,40,50,60,70,80]:\n",
    "    perf_mean.append(alg.classification(X[selected_features], y, classifier, param, 8))\n",
    "np.median(perf_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for LogisticRegression...\n",
      "0.7979007879643898\n",
      "Training for LogisticRegression...\n",
      "0.8033014604443176\n",
      "Training for LogisticRegression...\n",
      "0.8178474221766786\n",
      "Training for LogisticRegression...\n",
      "0.7833124930153432\n",
      "Training for LogisticRegression...\n",
      "0.7849865266111786\n",
      "Training for LogisticRegression...\n",
      "0.7986740263666241\n",
      "Training for LogisticRegression...\n",
      "0.8078743774918218\n",
      "Training for LogisticRegression...\n",
      "0.791082296901916\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.798287407165507)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = 'LogisticRegression'\n",
    "param = 1\n",
    "perf_mean = []\n",
    "for i in range(0,8):\n",
    "    perf_mean.append(alg.classification(X[selected_features], y, classifier, param, 8))\n",
    "np.median(perf_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for KNN...\n",
      "0.7694176571727591\n",
      "Training for KNN...\n",
      "0.7751611289612796\n",
      "Training for KNN...\n",
      "0.7630321261671263\n",
      "Training for KNN...\n",
      "0.7628710227439364\n",
      "Training for KNN...\n",
      "0.7911522230052686\n",
      "Training for KNN...\n",
      "0.7680954715689956\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.7687565643708774)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = 'KNN'\n",
    "param = 15\n",
    "perf_mean = []\n",
    "for param in [5,6,7,8,9,10]:\n",
    "    perf_mean.append(alg.classification(X[selected_features], y, classifier, param, 8))\n",
    "np.median(perf_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for RandomForest...\n",
      "0.753522667808382\n",
      "Training for RandomForest...\n",
      "0.7410696698869801\n",
      "Training for RandomForest...\n",
      "0.7439470243975299\n",
      "Training for RandomForest...\n",
      "0.7507314345246426\n",
      "Training for RandomForest...\n",
      "0.7556705056705058\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.7507314345246426)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = 'RandomForest'\n",
    "param = 100\n",
    "perf_mean = []\n",
    "for param in [60,70,80,90,100]:\n",
    "    perf_mean.append(alg.classification(X[selected_features], y, classifier, param, 8))\n",
    "np.median(perf_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for AdaBoost...\n",
      "0.7531408594546114\n",
      "Training for AdaBoost...\n",
      "0.7730883813306852\n",
      "Training for AdaBoost...\n",
      "0.7472527472527473\n",
      "Training for AdaBoost...\n",
      "0.7865935448483947\n",
      "Training for AdaBoost...\n",
      "0.7712340279440362\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.7712340279440362)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = 'AdaBoost'\n",
    "param = 40\n",
    "perf_mean = []\n",
    "for param in [60,70,80,90,100]:\n",
    "    perf_mean.append(alg.classification(X[selected_features], y, classifier, param, 8))\n",
    "np.median(perf_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for SVC...\n",
      "0.6921419718859483\n",
      "Training for SVC...\n",
      "0.7000787580146697\n",
      "Training for SVC...\n",
      "0.6910931217390281\n",
      "Training for SVC...\n",
      "0.6537994713325095\n",
      "Training for SVC...\n",
      "0.7188799119249893\n",
      "Training for SVC...\n",
      "0.6538042930095884\n",
      "Training for SVC...\n",
      "0.6882557505998603\n",
      "Training for SVC...\n",
      "0.6794399291411048\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.6896744361694442)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = 'SVC'\n",
    "param = 1\n",
    "perf_mean = []\n",
    "for i in range(0,8):\n",
    "    perf_mean.append(alg.classification(X[selected_features], y, classifier, param, 8))\n",
    "np.median(perf_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### prova con i sample per i grafi\n",
    "### partiamo da circa 0.72 come performance dirty per 70% di qualità"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13200 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.7094684168561306\n",
      "\n",
      "\n",
      "--- 6600 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.712228092567461\n",
      "\n",
      "\n",
      "--- 3960 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.6976867507424532\n",
      "\n",
      "\n",
      "--- 2640 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.6878443180633034\n",
      "\n",
      "\n",
      "--- 1320 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.6475472707571986\n",
      "\n",
      "\n",
      "--- 660 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.6108887529754827\n",
      "\n",
      "\n",
      "--- 132 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for DecisionTree...\n",
      "0.4894436122274997\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dirty_data as d\n",
    "import algorithms_class as a\n",
    "import pandas as pd\n",
    "\n",
    "m = 'DecisionTree'\n",
    "df = pd.read_csv(\"../dataset/weather.csv\")\n",
    "name_class = 'WeatherType'\n",
    "selected_features_only = ['Temperature', 'Precipitation', 'AtmosphericPressure']\n",
    "selected_features = ['Temperature', 'Precipitation', 'AtmosphericPressure','WeatherType']\n",
    "df = df[selected_features]\n",
    "\n",
    "param = {\n",
    "    'DecisionTree': 160,\n",
    "    'LogisticRegression': 1,\n",
    "    'KNN': 15,\n",
    "    'RandomForest': 20,\n",
    "    'AdaBoost': 40,\n",
    "    'SVC': 1\n",
    "}\n",
    "\n",
    "\n",
    "for p in [1,0.5,0.3,0.2,0.1,0.05,0.01]:\n",
    "    s = int(len(df)*p)\n",
    "    print('--- '+str(s)+' number of samples ---')\n",
    "    df_sample = df.sample(n=s).copy()\n",
    "    df_dirt = d.injection(df_sample, name_class, 0.7, 10, 1)\n",
    "    a.classification(df_dirt[selected_features_only], df_dirt[name_class], m, param[m], 4)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13200 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.7420618551354534\n",
      "\n",
      "\n",
      "--- 6600 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.7294237116323022\n",
      "\n",
      "\n",
      "--- 3960 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.7335683310103114\n",
      "\n",
      "\n",
      "--- 2640 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.7310744765754105\n",
      "\n",
      "\n",
      "--- 1320 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.7180195574573175\n",
      "\n",
      "\n",
      "--- 660 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.6945959399229524\n",
      "\n",
      "\n",
      "--- 132 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for RandomForest...\n",
      "0.6272408134306354\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = 'RandomForest'\n",
    "\n",
    "for p in [1,0.5,0.3,0.2,0.1,0.05,0.01]:\n",
    "    s = int(len(df)*p)\n",
    "    print('--- '+str(s)+' number of samples ---')\n",
    "    df_sample = df.sample(n=s).copy()\n",
    "    df_dirt = d.injection(df_sample, name_class, 0.7, 10, 1)\n",
    "    a.classification(df_dirt[selected_features_only], df_dirt[name_class], m, param[m], 4)\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13200 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.735333173422061\n",
      "\n",
      "\n",
      "--- 6600 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.7244936277999517\n",
      "\n",
      "\n",
      "--- 3960 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.7254587755172738\n",
      "\n",
      "\n",
      "--- 2640 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.7045503025781839\n",
      "\n",
      "\n",
      "--- 1320 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.6568563798868383\n",
      "\n",
      "\n",
      "--- 660 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.6188844779460378\n",
      "\n",
      "\n",
      "--- 132 number of samples ---\n",
      "saved dirty dataset 70%\n",
      "Training for AdaBoost...\n",
      "0.5977593048713739\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = 'AdaBoost'\n",
    "\n",
    "for p in [1,0.5,0.3,0.2,0.1,0.05,0.01]:\n",
    "    s = int(len(df)*p)\n",
    "    print('--- '+str(s)+' number of samples ---')\n",
    "    df_sample = df.sample(n=s).copy()\n",
    "    df_dirt = d.injection(df_sample, name_class, 0.7, 10, 1)\n",
    "    a.classification(df_dirt[selected_features_only], df_dirt[name_class], m, param[m], 4)\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
