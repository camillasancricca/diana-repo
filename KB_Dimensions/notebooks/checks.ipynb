{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from scripts import dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "original_data = pd.read_json(\"../kb/KBR.json\")\n",
    "\n",
    "dimensions = original_data.dimension.unique()\n",
    "models = original_data.model.unique()\n",
    "datasets = original_data.name.unique()\n",
    "\n",
    "datasets_fd = [\"BachChoralHarmony\", \"bank\", \"cancer\", \"mushrooms\", \"soybean\"]\n",
    "\n",
    "data_copy = dataset.get_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "### controllo sulla varianza degli score dei vicini\n",
    "### la varianza dei \"vicini\" non è mai superiore a 0.07 su una scala di impatto tra 0 e 1\n",
    "### inoltre, la varianza è superiore a 0.02 nel 18% dei casi, e superiore a 0.05 nel 3% dei casi\n",
    "#   superiore a 0.02 -> 0.18622222222222223\n",
    "#   superiore a 0.03 -> 0.11511111111111111\n",
    "#   superiore a 0.04 -> 0.06755555555555555\n",
    "#   superiore a 0.05 -> 0.03688888888888889\n",
    "#   superiore a 0.06 -> 0.007555555555555556"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "419\n",
      "0.18622222222222223\n",
      "0.03\n",
      "259\n",
      "0.11511111111111111\n",
      "0.04\n",
      "152\n",
      "0.06755555555555555\n",
      "0.05\n",
      "83\n",
      "0.03688888888888889\n",
      "0.06\n",
      "17\n",
      "0.007555555555555556\n",
      "0.07\n",
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "total = len(datasets)*len(models)*len(dimensions)*5\n",
    "for th in [0.02, 0.03, 0.04, 0.05, 0.06, 0.07]:\n",
    "    count = 0\n",
    "    for dataset in datasets:\n",
    "        for model in models:\n",
    "            for dimension in dimensions:\n",
    "\n",
    "                data = data_copy.copy()\n",
    "\n",
    "                if dimension == \"consistency\" and (dataset in datasets_fd):\n",
    "\n",
    "                        df = data[(data[\"model\"] == model) & (data[\"dimension\"] == dimension) & ((data[\"name\"] == \"BachChoralHarmony\") | (data[\"name\"] == \"mushrooms\") | (data[\"name\"] == \"bank\") | (data[\"name\"] == \"cancer\") | (data[\"name\"] == \"soybean\"))].copy()\n",
    "\n",
    "                        train = df[df[\"name\"] != dataset]\n",
    "                        test = df[df[\"name\"] == dataset]\n",
    "\n",
    "                        columns = df.columns\n",
    "                        features = columns.drop([\"name\",\"dimension\",\"model\",\"score\",\"impact\",\"p_correlated_features_0.5\",\"p_correlated_features_0.6\",\"p_correlated_features_0.7\",\"p_correlated_features_0.8\",\"p_correlated_features_0.9\"])\n",
    "\n",
    "                        X_train = train[features]\n",
    "                        y_train = train[\"impact\"]\n",
    "                        X_test = test[features]\n",
    "                        y_test = test[\"impact\"]\n",
    "\n",
    "                        X_train = StandardScaler().fit_transform(X_train)\n",
    "                        X_train = np.nan_to_num(X_train)\n",
    "\n",
    "                        X_test = StandardScaler().fit_transform(X_test)\n",
    "                        X_test = np.nan_to_num(X_test)\n",
    "\n",
    "                        knn = KNeighborsRegressor(n_neighbors=14, metric='manhattan')\n",
    "                        knn.fit(X_train, y_train)\n",
    "                        y_pred = knn.predict(X_test)\n",
    "                        error = root_mean_squared_error(y_test, y_pred)\n",
    "                        #print(dataset+\": \"+str(error))\n",
    "\n",
    "                        ### distances\n",
    "                        distances = knn.kneighbors(X_test, n_neighbors=14, return_distance=False)\n",
    "                        distances = pd.DataFrame(distances)\n",
    "\n",
    "                        ### list of datasets names\n",
    "                        names = df[df[\"name\"] != dataset].copy()\n",
    "                        names = names.reset_index(drop=True)\n",
    "                        names[\"name\"] = names[\"name\"] + \"_\" + names[\"perc\"].astype(str)\n",
    "                        names = names.reset_index()\n",
    "\n",
    "                        all_names = df.copy()\n",
    "                        all_names = all_names.reset_index(drop=True)\n",
    "                        all_names[\"name\"] = all_names[\"name\"] + \"_\" + all_names[\"perc\"].astype(str)\n",
    "                        all_names = all_names.reset_index()\n",
    "\n",
    "                        for i in range(0,len(names)):\n",
    "                            distances = distances.replace(names[\"index\"][i],names[\"name\"][i])\n",
    "\n",
    "                        similar = []\n",
    "                        for i in range(0,len(distances)):\n",
    "                            for j in range(0,14):\n",
    "                                similar.append(distances.loc[i][j])\n",
    "\n",
    "                            impacts = []\n",
    "                            for sim in similar:\n",
    "\n",
    "                                impact = all_names[((all_names.name == sim))].impact\n",
    "                                impacts.append(impact.values[0])\n",
    "\n",
    "                            if statistics.variance(impacts) > th:\n",
    "                                #print(dataset+\": \"+str(error))\n",
    "                                #print(statistics.variance(impacts))\n",
    "                                count = count + 1\n",
    "\n",
    "                            impacts = []\n",
    "\n",
    "                elif dimension != \"consistency\":\n",
    "\n",
    "                    df = data[(data[\"model\"] == model) & (data[\"dimension\"] == dimension)].copy()\n",
    "\n",
    "                    train = df[df[\"name\"] != dataset]\n",
    "                    test = df[df[\"name\"] == dataset]\n",
    "\n",
    "                    columns = df.columns\n",
    "                    features = columns.drop([\"name\",\"dimension\",\"model\",\"score\",\"impact\",\"p_correlated_features_0.5\",\"p_correlated_features_0.6\",\"p_correlated_features_0.7\",\"p_correlated_features_0.8\",\"p_correlated_features_0.9\"])\n",
    "\n",
    "                    X_train = train[features]\n",
    "                    y_train = train[\"impact\"]\n",
    "                    X_test = test[features]\n",
    "                    y_test = test[\"impact\"]\n",
    "\n",
    "                    X_train = StandardScaler().fit_transform(X_train)\n",
    "                    X_train = np.nan_to_num(X_train)\n",
    "\n",
    "                    X_test = StandardScaler().fit_transform(X_test)\n",
    "                    X_test = np.nan_to_num(X_test)\n",
    "\n",
    "                    knn = KNeighborsRegressor(n_neighbors=14, metric='manhattan')\n",
    "                    knn.fit(X_train, y_train)\n",
    "                    y_pred = knn.predict(X_test)\n",
    "                    error = root_mean_squared_error(y_test, y_pred)\n",
    "                    #print(dataset+\": \"+str(error))\n",
    "\n",
    "                    ### distances\n",
    "                    distances = knn.kneighbors(X_test, n_neighbors=14, return_distance=False)\n",
    "                    distances = pd.DataFrame(distances)\n",
    "\n",
    "                    ### list of datasets names\n",
    "                    names = df[df[\"name\"] != dataset].copy()\n",
    "                    names = names.reset_index(drop=True)\n",
    "                    names[\"name\"] = names[\"name\"] + \"_\" + names[\"perc\"].astype(str)\n",
    "                    names = names.reset_index()\n",
    "\n",
    "                    all_names = df.copy()\n",
    "                    all_names = all_names.reset_index(drop=True)\n",
    "                    all_names[\"name\"] = all_names[\"name\"] + \"_\" + all_names[\"perc\"].astype(str)\n",
    "                    all_names = all_names.reset_index()\n",
    "\n",
    "                    for i in range(0,len(names)):\n",
    "                        distances = distances.replace(names[\"index\"][i],names[\"name\"][i])\n",
    "\n",
    "                    similar = []\n",
    "                    for i in range(0,len(distances)):\n",
    "                        for j in range(0,14):\n",
    "                            similar.append(distances.loc[i][j])\n",
    "\n",
    "                        impacts = []\n",
    "                        for sim in similar:\n",
    "\n",
    "                            impact = all_names[((all_names.name == sim))].impact\n",
    "                            impacts.append(impact.values[0])\n",
    "\n",
    "                        if statistics.variance(impacts) > th:\n",
    "                            #print(dataset+\": \"+str(error))\n",
    "                            #print(statistics.variance(impacts))\n",
    "                            count = count + 1\n",
    "\n",
    "                        impacts = []\n",
    "    print(th)\n",
    "    print(count)\n",
    "    print(count/total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "### controllo sulla distanza dei vicini\n",
    "### studio sulla varianza della distanza tra vicini"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "variance = []\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        for dimension in dimensions:\n",
    "\n",
    "            data = data_copy.copy()\n",
    "\n",
    "            if dimension == \"consistency\" and (dataset in datasets_fd):\n",
    "\n",
    "                    df = data[(data[\"model\"] == model) & (data[\"dimension\"] == dimension) & ((data[\"name\"] == \"BachChoralHarmony\") | (data[\"name\"] == \"mushrooms\") | (data[\"name\"] == \"bank\") | (data[\"name\"] == \"cancer\") | (data[\"name\"] == \"soybean\"))].copy()\n",
    "\n",
    "                    train = df[df[\"name\"] != dataset]\n",
    "                    test = df[df[\"name\"] == dataset]\n",
    "\n",
    "                    columns = df.columns\n",
    "                    features = columns.drop([\"name\",\"dimension\",\"model\",\"score\",\"impact\",\"p_correlated_features_0.5\",\"p_correlated_features_0.6\",\"p_correlated_features_0.7\",\"p_correlated_features_0.8\",\"p_correlated_features_0.9\"])\n",
    "\n",
    "                    X_train = train[features]\n",
    "                    y_train = train[\"impact\"]\n",
    "                    X_test = test[features]\n",
    "                    y_test = test[\"impact\"]\n",
    "\n",
    "                    X_train = StandardScaler().fit_transform(X_train)\n",
    "                    X_train = np.nan_to_num(X_train)\n",
    "\n",
    "                    X_test = StandardScaler().fit_transform(X_test)\n",
    "                    X_test = np.nan_to_num(X_test)\n",
    "\n",
    "                    knn = KNeighborsRegressor(n_neighbors=14, metric='manhattan')\n",
    "                    knn.fit(X_train, y_train)\n",
    "                    y_pred = knn.predict(X_test)\n",
    "                    error = root_mean_squared_error(y_test, y_pred)\n",
    "                    #print(dataset+\": \"+str(error))\n",
    "\n",
    "                    ### distances\n",
    "                    distances = knn.kneighbors(X_test, n_neighbors=14, return_distance=True)\n",
    "                    #distances = pd.DataFrame(distances)\n",
    "\n",
    "                    #print(dataset)\n",
    "                    #print(model)\n",
    "                    #print(dimension)\n",
    "                    for i in range(0,len(distances[0])):\n",
    "                        #print(\"min \"+str(distances[0][i].min()))\n",
    "                        #print(\"max \"+str(distances[0][i].max()))\n",
    "                        #print(\"var \"+str(distances[0][i].var()))\n",
    "                        variance.append([dataset, model, dimension, distances[0][i].min(), distances[0][i].max(), distances[0][i].var()])\n",
    "\n",
    "\n",
    "            elif dimension != \"consistency\":\n",
    "\n",
    "                df = data[(data[\"model\"] == model) & (data[\"dimension\"] == dimension)].copy()\n",
    "\n",
    "                train = df[df[\"name\"] != dataset]\n",
    "                test = df[df[\"name\"] == dataset]\n",
    "\n",
    "                columns = df.columns\n",
    "                features = columns.drop([\"name\",\"dimension\",\"model\",\"score\",\"impact\",\"p_correlated_features_0.5\",\"p_correlated_features_0.6\",\"p_correlated_features_0.7\",\"p_correlated_features_0.8\",\"p_correlated_features_0.9\"])\n",
    "\n",
    "                X_train = train[features]\n",
    "                y_train = train[\"impact\"]\n",
    "                X_test = test[features]\n",
    "                y_test = test[\"impact\"]\n",
    "\n",
    "                X_train = StandardScaler().fit_transform(X_train)\n",
    "                X_train = np.nan_to_num(X_train)\n",
    "\n",
    "                X_test = StandardScaler().fit_transform(X_test)\n",
    "                X_test = np.nan_to_num(X_test)\n",
    "\n",
    "                knn = KNeighborsRegressor(n_neighbors=14, metric='manhattan')\n",
    "                knn.fit(X_train, y_train)\n",
    "                y_pred = knn.predict(X_test)\n",
    "                error = root_mean_squared_error(y_test, y_pred)\n",
    "                #print(dataset+\": \"+str(error))\n",
    "\n",
    "                ### distances\n",
    "                distances = knn.kneighbors(X_test, n_neighbors=14, return_distance=True)\n",
    "                #distances = pd.DataFrame(distances)\n",
    "\n",
    "                #print(dataset)\n",
    "                #print(model)\n",
    "                #print(dimension)\n",
    "                for i in range(0,len(distances[0])):\n",
    "                    #print(\"min \"+str(distances[0][i].min()))\n",
    "                    #print(\"max \"+str(distances[0][i].max()))\n",
    "                    #print(\"var \"+str(distances[0][i].var()))\n",
    "                    variance.append([dataset, model, dimension, distances[0][i].min(), distances[0][i].max(), distances[0][i].var()])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "variance = pd.DataFrame(variance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "variance.columns = [\"dataset\",\"model\",\"dim\",\"min\",\"max\",\"var\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "### la varianza delle distanze è in media 10, oscilla tra 0.4 e 181, ma il 75% delle varianze delle distanze è inferiore a 7.8, tenendo conto che le distanze variano tra 18.7 e 80\n",
    "### direi che la distanza è abbastanza variante -- adesso proviamo con la cosine distance per farci un'idea di quanto sono vicini/distanti"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "                    dataset         model           dim        min        max  \\\n0                   abalone  DecisionTree  completeness  36.679245  47.233663   \n1                   abalone  DecisionTree  completeness  39.212465  43.212252   \n2                   abalone  DecisionTree  completeness  31.665653  35.261860   \n3                   abalone  DecisionTree  completeness  40.611252  44.682739   \n4                   abalone  DecisionTree  completeness  38.703744  46.145853   \n...                     ...           ...           ...        ...        ...   \n1645  wall-robot-navigation           SVC      accuracy  42.510716  51.103526   \n1646  wall-robot-navigation           SVC      accuracy  26.761741  33.887684   \n1647  wall-robot-navigation           SVC      accuracy  24.318314  29.684561   \n1648  wall-robot-navigation           SVC      accuracy  24.055611  31.892165   \n1649  wall-robot-navigation           SVC      accuracy  36.840278  50.271811   \n\n            var  \n0     15.486477  \n1      1.688836  \n2      1.141792  \n3      1.102592  \n4      4.126130  \n...         ...  \n1645   6.648753  \n1646   5.513065  \n1647   1.863979  \n1648   6.001211  \n1649  12.595480  \n\n[1650 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>dim</th>\n      <th>min</th>\n      <th>max</th>\n      <th>var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>36.679245</td>\n      <td>47.233663</td>\n      <td>15.486477</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>39.212465</td>\n      <td>43.212252</td>\n      <td>1.688836</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>31.665653</td>\n      <td>35.261860</td>\n      <td>1.141792</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>40.611252</td>\n      <td>44.682739</td>\n      <td>1.102592</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>38.703744</td>\n      <td>46.145853</td>\n      <td>4.126130</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1645</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>42.510716</td>\n      <td>51.103526</td>\n      <td>6.648753</td>\n    </tr>\n    <tr>\n      <th>1646</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>26.761741</td>\n      <td>33.887684</td>\n      <td>5.513065</td>\n    </tr>\n    <tr>\n      <th>1647</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>24.318314</td>\n      <td>29.684561</td>\n      <td>1.863979</td>\n    </tr>\n    <tr>\n      <th>1648</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>24.055611</td>\n      <td>31.892165</td>\n      <td>6.001211</td>\n    </tr>\n    <tr>\n      <th>1649</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>36.840278</td>\n      <td>50.271811</td>\n      <td>12.595480</td>\n    </tr>\n  </tbody>\n</table>\n<p>1650 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "               min          max          var\ncount  1650.000000  1650.000000  1650.000000\nmean     34.607057    42.622860    10.175873\nstd       9.425985    11.539102    20.544745\nmin      18.694570    24.335618     0.477754\n25%      27.402358    33.353245     2.256630\n50%      32.442520    39.975037     4.249278\n75%      39.792358    49.852481     7.849047\nmax      66.165040    79.156666   181.283421",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min</th>\n      <th>max</th>\n      <th>var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1650.000000</td>\n      <td>1650.000000</td>\n      <td>1650.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>34.607057</td>\n      <td>42.622860</td>\n      <td>10.175873</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.425985</td>\n      <td>11.539102</td>\n      <td>20.544745</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.694570</td>\n      <td>24.335618</td>\n      <td>0.477754</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27.402358</td>\n      <td>33.353245</td>\n      <td>2.256630</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>32.442520</td>\n      <td>39.975037</td>\n      <td>4.249278</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>39.792358</td>\n      <td>49.852481</td>\n      <td>7.849047</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>66.165040</td>\n      <td>79.156666</td>\n      <td>181.283421</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "variance = []\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        for dimension in dimensions:\n",
    "\n",
    "            data = data_copy.copy()\n",
    "\n",
    "            if dimension == \"consistency\" and (dataset in datasets_fd):\n",
    "\n",
    "                    df = data[(data[\"model\"] == model) & (data[\"dimension\"] == dimension) & ((data[\"name\"] == \"BachChoralHarmony\") | (data[\"name\"] == \"mushrooms\") | (data[\"name\"] == \"bank\") | (data[\"name\"] == \"cancer\") | (data[\"name\"] == \"soybean\"))].copy()\n",
    "\n",
    "                    train = df[df[\"name\"] != dataset]\n",
    "                    test = df[df[\"name\"] == dataset]\n",
    "\n",
    "                    columns = df.columns\n",
    "                    features = columns.drop([\"name\",\"dimension\",\"model\",\"score\",\"impact\",\"p_correlated_features_0.5\",\"p_correlated_features_0.6\",\"p_correlated_features_0.7\",\"p_correlated_features_0.8\",\"p_correlated_features_0.9\"])\n",
    "\n",
    "                    X_train = train[features]\n",
    "                    y_train = train[\"impact\"]\n",
    "                    X_test = test[features]\n",
    "                    y_test = test[\"impact\"]\n",
    "\n",
    "                    X_train = StandardScaler().fit_transform(X_train)\n",
    "                    X_train = np.nan_to_num(X_train)\n",
    "\n",
    "                    X_test = StandardScaler().fit_transform(X_test)\n",
    "                    X_test = np.nan_to_num(X_test)\n",
    "\n",
    "                    knn = KNeighborsRegressor(n_neighbors=14, metric='cosine')\n",
    "                    knn.fit(X_train, y_train)\n",
    "                    y_pred = knn.predict(X_test)\n",
    "                    error = root_mean_squared_error(y_test, y_pred)\n",
    "                    #print(dataset+\": \"+str(error))\n",
    "\n",
    "                    ### distances\n",
    "                    distances = knn.kneighbors(X_test, n_neighbors=14, return_distance=True)\n",
    "                    #distances = pd.DataFrame(distances)\n",
    "\n",
    "                    #print(dataset)\n",
    "                    #print(model)\n",
    "                    #print(dimension)\n",
    "                    for i in range(0,len(distances[0])):\n",
    "                        #print(\"min \"+str(distances[0][i].min()))\n",
    "                        #print(\"max \"+str(distances[0][i].max()))\n",
    "                        #print(\"var \"+str(distances[0][i].var()))\n",
    "                        variance.append([dataset, model, dimension, distances[0][i].min(), distances[0][i].max(), distances[0][i].var()])\n",
    "\n",
    "\n",
    "            elif dimension != \"consistency\":\n",
    "\n",
    "                df = data[(data[\"model\"] == model) & (data[\"dimension\"] == dimension)].copy()\n",
    "\n",
    "                train = df[df[\"name\"] != dataset]\n",
    "                test = df[df[\"name\"] == dataset]\n",
    "\n",
    "                columns = df.columns\n",
    "                features = columns.drop([\"name\",\"dimension\",\"model\",\"score\",\"impact\",\"p_correlated_features_0.5\",\"p_correlated_features_0.6\",\"p_correlated_features_0.7\",\"p_correlated_features_0.8\",\"p_correlated_features_0.9\"])\n",
    "\n",
    "                X_train = train[features]\n",
    "                y_train = train[\"impact\"]\n",
    "                X_test = test[features]\n",
    "                y_test = test[\"impact\"]\n",
    "\n",
    "                X_train = StandardScaler().fit_transform(X_train)\n",
    "                X_train = np.nan_to_num(X_train)\n",
    "\n",
    "                X_test = StandardScaler().fit_transform(X_test)\n",
    "                X_test = np.nan_to_num(X_test)\n",
    "\n",
    "                knn = KNeighborsRegressor(n_neighbors=14, metric='cosine')\n",
    "                knn.fit(X_train, y_train)\n",
    "                y_pred = knn.predict(X_test)\n",
    "                error = root_mean_squared_error(y_test, y_pred)\n",
    "                #print(dataset+\": \"+str(error))\n",
    "\n",
    "                ### distances\n",
    "                distances = knn.kneighbors(X_test, n_neighbors=14, return_distance=True)\n",
    "                #distances = pd.DataFrame(distances)\n",
    "\n",
    "                #print(dataset)\n",
    "                #print(model)\n",
    "                #print(dimension)\n",
    "                for i in range(0,len(distances[0])):\n",
    "                    #print(\"min \"+str(distances[0][i].min()))\n",
    "                    #print(\"max \"+str(distances[0][i].max()))\n",
    "                    #print(\"var \"+str(distances[0][i].var()))\n",
    "                    variance.append([dataset, model, dimension, distances[0][i].min(), distances[0][i].max(), distances[0][i].var()])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                    dataset         model           dim       min       max  \\\n0                   abalone  DecisionTree  completeness  0.570701  0.670549   \n1                   abalone  DecisionTree  completeness  0.661850  0.746765   \n2                   abalone  DecisionTree  completeness  0.583624  0.804369   \n3                   abalone  DecisionTree  completeness  0.487606  0.788665   \n4                   abalone  DecisionTree  completeness  0.590355  0.728730   \n...                     ...           ...           ...       ...       ...   \n1645  wall-robot-navigation           SVC      accuracy  0.324261  0.771650   \n1646  wall-robot-navigation           SVC      accuracy  0.547096  0.719327   \n1647  wall-robot-navigation           SVC      accuracy  0.831363  0.858046   \n1648  wall-robot-navigation           SVC      accuracy  0.473550  0.727864   \n1649  wall-robot-navigation           SVC      accuracy  0.491050  0.663914   \n\n           var  \n0     0.000938  \n1     0.000711  \n2     0.005750  \n3     0.009976  \n4     0.001530  \n...        ...  \n1645  0.023884  \n1646  0.002004  \n1647  0.000058  \n1648  0.007164  \n1649  0.003991  \n\n[1650 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>dim</th>\n      <th>min</th>\n      <th>max</th>\n      <th>var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>0.570701</td>\n      <td>0.670549</td>\n      <td>0.000938</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>0.661850</td>\n      <td>0.746765</td>\n      <td>0.000711</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>0.583624</td>\n      <td>0.804369</td>\n      <td>0.005750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>0.487606</td>\n      <td>0.788665</td>\n      <td>0.009976</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abalone</td>\n      <td>DecisionTree</td>\n      <td>completeness</td>\n      <td>0.590355</td>\n      <td>0.728730</td>\n      <td>0.001530</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1645</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>0.324261</td>\n      <td>0.771650</td>\n      <td>0.023884</td>\n    </tr>\n    <tr>\n      <th>1646</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>0.547096</td>\n      <td>0.719327</td>\n      <td>0.002004</td>\n    </tr>\n    <tr>\n      <th>1647</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>0.831363</td>\n      <td>0.858046</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>1648</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>0.473550</td>\n      <td>0.727864</td>\n      <td>0.007164</td>\n    </tr>\n    <tr>\n      <th>1649</th>\n      <td>wall-robot-navigation</td>\n      <td>SVC</td>\n      <td>accuracy</td>\n      <td>0.491050</td>\n      <td>0.663914</td>\n      <td>0.003991</td>\n    </tr>\n  </tbody>\n</table>\n<p>1650 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = pd.DataFrame(variance)\n",
    "variance.columns = [\"dataset\", \"model\", \"dim\", \"min\", \"max\", \"var\"]\n",
    "variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "               min          max           var\ncount  1650.000000  1650.000000  1.650000e+03\nmean      0.581191     0.796119  5.872621e-03\nstd       0.125917     0.103145  6.302457e-03\nmin       0.245217     0.638208  7.923826e-33\n25%       0.491147     0.729437  1.742012e-03\n50%       0.581122     0.775277  3.758877e-03\n75%       0.671192     0.825691  7.811235e-03\nmax       1.000000     1.157312  3.878080e-02",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min</th>\n      <th>max</th>\n      <th>var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1650.000000</td>\n      <td>1650.000000</td>\n      <td>1.650000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.581191</td>\n      <td>0.796119</td>\n      <td>5.872621e-03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.125917</td>\n      <td>0.103145</td>\n      <td>6.302457e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.245217</td>\n      <td>0.638208</td>\n      <td>7.923826e-33</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.491147</td>\n      <td>0.729437</td>\n      <td>1.742012e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.581122</td>\n      <td>0.775277</td>\n      <td>3.758877e-03</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.671192</td>\n      <td>0.825691</td>\n      <td>7.811235e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.157312</td>\n      <td>3.878080e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "### tenendo conto che la cosine distance varia tra 0 (identical), 1 (no correlation), e 2 (totally different)\n",
    "### la varianza è veramente poca considerato che varia tra 0 e 2 ho una varianza media di 0.00587\n",
    "### al massimo la varianza è di 0.03 sempre variando tra 0 e 2\n",
    "### il 75% dei casi ha una variaza minore di 0.007\n",
    "### i vicini sono sempre molto vicini"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
